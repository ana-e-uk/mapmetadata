{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d78d8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('/Users/bean/Documents/Doctorate/1Research/MapMetadata/mapmetadata/data_partiton_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f23465b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ac619",
   "metadata": {},
   "source": [
    "### Code for DataPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8e61cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "import osmnx as ox\n",
    "\n",
    "class DataPartition:\n",
    "    def __init__(self, df):\n",
    "\n",
    "        # CONFIGS\n",
    "        self.max_time_diff = pd.Timedelta(minutes=2)\n",
    "        self.k = 4\n",
    "        self.network_type = 'drive'\n",
    "\n",
    "        # DATASET\n",
    "        self.traj_ids = df['traj_id'].to_list()\n",
    "        self.timestamps = self.get_timestamp_list(col=df['timestamp'])\n",
    "        self.latitudes = df['latitude'].to_list()\n",
    "        self.longitudes = df['longitude'].to_list()\n",
    "\n",
    "        self.num_points = len(df)\n",
    "\n",
    "        # INDEXES\n",
    "        self.time_group_idx, self.time_idx_exp, self.speeds = self.get_time_group_idx()\n",
    "        self.space_group_mbrs, self.space_group_idx = self.get_space_groups()\n",
    "\n",
    "        # DATA SUBSETS\n",
    "            # lat/long together\n",
    "        # self.base_df = np.stack([self.longitudes, self.latitudes, self.speeds]).transpose()\n",
    "        # self.points_in_time_groups = np.split(self.base_df, self.time_group_idx)\n",
    "            # lat/long separate\n",
    "        self.lats_in_time_groups = np.split(self.latitudes, self.time_group_idx)\n",
    "        self.lons_in_time_groups = np.split(self.longitudes, self.time_group_idx)\n",
    "\n",
    "    def print_group_indices(self):\n",
    "\n",
    "        print(f\"time group index: {self.time_group_idx}\\n\")\n",
    "        print(f\"time index expanded: {self.time_idx_exp}\\n\")\n",
    "        print(f\"space group MBRs: {self.space_group_mbrs}\\n\")\n",
    "        print(f\"space group index: {self.space_group_idx}\\n\")\n",
    "\n",
    "        return\n",
    "\n",
    "    def get_timestamp_list(self, col):\n",
    "        \"\"\"Convert timestamps to datetime objects\"\"\"\n",
    "        dt = pd.to_datetime(col, errors = 'coerce')\n",
    "        return dt.to_list()\n",
    "\n",
    "    def get_time_group_idx(self):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "            List of index intervals defining each time group\n",
    "                All points in a time group are within the self.max_time_diff time difference\n",
    "                All points in a time group are from the same trajectory\n",
    "            Estimated speed at each point\n",
    "                The last two points are given the same speed\n",
    "        \"\"\"\n",
    "        time_group_intervals = []\n",
    "        time_intervals_expanded = []\n",
    "        time_diff = []\n",
    "        dist_diff = []\n",
    "        s = 0\n",
    "        group_time_diff = pd.Timedelta(minutes=0)\n",
    "        prev_id = self.traj_ids[0]\n",
    "        prev_lat = self.latitudes[0]\n",
    "        prev_lon = self.longitudes[0]\n",
    "        prev_timestamp = self.timestamps[0]\n",
    "\n",
    "        for i in range(1, (self.num_points-1)):\n",
    "\n",
    "            cur_id = self.traj_ids[i]\n",
    "            cur_lat = self.latitudes[i]\n",
    "            cur_lon = self.longitudes[i]\n",
    "            cur_timestamp = self.timestamps[i]\n",
    "\n",
    "            if cur_id == prev_id:\n",
    "                time_diff.append((cur_timestamp - prev_timestamp).total_seconds())\n",
    "                dist_diff.append(round(np.linalg.norm(np.array([cur_lon, cur_lat], dtype=np.float32) - np.array([prev_lon, prev_lat], dtype=np.float32)), 2))\n",
    "\n",
    "                group_time_diff = cur_timestamp - self.timestamps[s]\n",
    "                if (group_time_diff > self.max_time_diff):\n",
    "                    time_group_intervals.append((s,i))\n",
    "                    time_intervals_expanded.append(np.arange(s,i))\n",
    "                    s = i\n",
    "            else:\n",
    "                # last two points of prev trajectory get same speed\n",
    "                time_diff.append(time_diff[-1])\n",
    "                dist_diff.append(dist_diff[-1])\n",
    "                prev_id = cur_id\n",
    "            \n",
    "            prev_lat = cur_lat\n",
    "            prev_lon = cur_lon\n",
    "            prev_timestamp = cur_timestamp\n",
    "\n",
    "        # last index - check if ids of last two points are the same, add correct ids to lists\n",
    "        last_i = self.num_points - 1    # == i + 1\n",
    "        cur_id = self.traj_ids[last_i]\n",
    "\n",
    "        if cur_id != prev_id:   # corner case - last point not in same trajectory as penultimate point\n",
    "            # add last group from loop\n",
    "            time_group_intervals.append((s, i))\n",
    "            time_intervals_expanded.append(np.arange(s, last_i))    # need last_i == i + 1 because we want [s, i]\n",
    "            time_diff.append(time_diff[-1])\n",
    "            dist_diff.append(dist_diff[-1])\n",
    "\n",
    "            # add last point\n",
    "            time_group_intervals.append(last_i, last_i)\n",
    "            time_intervals_expanded.append(np.arange(last_i, self.num_points))\n",
    "            time_diff.append(None)\n",
    "            dist_diff.append(None)\n",
    "\n",
    "        else:   # standard case - last point in same trajectory as penultimate point\n",
    "            time_group_intervals.append((s, last_i))\n",
    "            time_intervals_expanded.append(np.arange(s, self.num_points))\n",
    "\n",
    "            cur_lat = self.latitudes[last_i]\n",
    "            cur_lon = self.longitudes[last_i]\n",
    "            time_diff.append((self.timestamps[last_i] - self.timestamps[i]).total_seconds())\n",
    "            dist_diff.append(round(np.linalg.norm(np.array([cur_lon, cur_lat], dtype=np.float32) - np.array([prev_lon, prev_lat], dtype=np.float32)), 2))\n",
    "\n",
    "        indices = [end for _, end in time_group_intervals[:-1]]  #TODO: make this the time_group_idx if we only need these vals   \n",
    "\n",
    "        dt = [d/t for d, t in zip(dist_diff,time_diff)]\n",
    "        dt.append(dt[-1])   # last two points have the same value\n",
    "\n",
    "        return indices, time_intervals_expanded, dt\n",
    "    \n",
    "    def get_extrema(self):\n",
    "        \"\"\"\n",
    "        CALLED BY GET_SPACE_GROUPS\n",
    "\n",
    "        Get the min/max lat/long of the first and last points in a time group\n",
    "        Return [min lat, max lat] , [min_long, max_long]\n",
    "        \"\"\"\n",
    "        # indices = [end for _, end in self.time_group_idx[:-1]]  #TODO: make this the time_group_idx if we only need these vals   \n",
    "\n",
    "        # [time group 1 [first point lat/lon, last point lat/lon], time group 2 [ first point, last point], ...]\n",
    "        first_last_lats = np.matrix([[l[0], l[-1]] for l in np.split(self.latitudes, self.time_group_idx)])\n",
    "        first_last_lons = np.matrix([[l[0], l[-1]] for l in np.split(self.longitudes, self.time_group_idx)])\n",
    "        \n",
    "        sorted_lats = np.asarray(np.sort(first_last_lats, axis=1))\n",
    "        sorted_lons = np.asarray(np.sort(first_last_lons, axis=1))\n",
    "\n",
    "        return sorted_lats, sorted_lons\n",
    "\n",
    "    def get_bbox(self, lat, lon, labels, i):\n",
    "        \"\"\"\n",
    "        CALLED BY GET_SPACE_GROUPS\n",
    "\n",
    "        Given a space group label, get all the lat/lon values [time group values] that are in that space group\n",
    "            (lat/lon are list of [min val, max val] of each time group, and you mask by space group label i)\n",
    "        Return (min_long, min_lat, max_long, max_lat) == (left, bottom, right, top)\n",
    "        \"\"\"\n",
    "        g_lat = np.matrix([row for row, l in zip(lat, labels) if l == i])\n",
    "        g_lon = np.matrix([row for row, l in zip(lon, labels) if l == i])\n",
    "        return (np.min(g_lon), np.min(g_lat), np.max(g_lon), np.max(g_lat))\n",
    "\n",
    "    def get_space_groups(self):\n",
    "        \"\"\"\n",
    "        NOTES:  Number of space groups is the number of road networks\n",
    "                We want to get the smallest number of road networks that are small enough\n",
    "                to make map matching fast, so we cluster all the MBRs into k groups\n",
    "\n",
    "        Return:\n",
    "            space_groups: mbr of each space group (there are k groups)\n",
    "                mbr = [min_long, min_lat, max_long, max_lat] == [left, bottom, right, top]\n",
    "            labels: list of corresponding space group index for each time group\n",
    "                index is the index of the space group each time group belongs in\n",
    "        \"\"\"\n",
    "        sorted_lats, sorted_lons = self.get_extrema()\n",
    "        mbrs = np.hstack([sorted_lats, sorted_lons])\n",
    "\n",
    "        centroids = [( (x1+x2)/2, (y1+y2)/2 ) for y1, y2, x1, x2 in mbrs]\n",
    "        kmeans = KMeans(n_clusters = self.k).fit(centroids)\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        space_groups = []\n",
    "        for i in range(self.k):\n",
    "            space_groups.append(self.get_bbox(lat=sorted_lats, lon=sorted_lons, labels=labels, i=i))\n",
    "\n",
    "        return space_groups, labels\n",
    "    \n",
    "    def get_road_network(self, mbr):\n",
    "        \"\"\"\n",
    "        CALLED BY MAP_MATCH\n",
    "\n",
    "        Return OSM road network within the given space group mbr\n",
    "        \"\"\"\n",
    "        return ox.graph_from_bbox(bbox=mbr, network_type=self.network_type, retain_all=True, truncate_by_edge=True, simplify=False)\n",
    "\n",
    "    def get_all_space_group_points(self, i):\n",
    "        \"\"\"\n",
    "        CALLED BY MAP_MATCH\n",
    "\n",
    "        Given a space group label\n",
    "        Return all the point coordinates that correspond to that space group as a list\n",
    "            need to return lat and long separately because osm.nearest_edges takes them separately\n",
    "            if it is no longer needed, can do them all at once:\n",
    "                points_in_space_group = [time_group for time_group, space_idx in zip(self.points_in_time_groups, self.space_group_idx) if space_idx == i]\n",
    "                return np.vstack(points_in_space_group).tolist()\n",
    "        \"\"\"\n",
    "        lats_in_space_group = np.hstack([time_group for time_group, space_idx in zip(self.lats_in_time_groups, self.space_group_idx) if space_idx == i]).tolist()\n",
    "        lons_in_space_group = np.hstack([time_group for time_group, space_idx in zip(self.lons_in_time_groups, self.space_group_idx) if space_idx == i]).tolist()\n",
    "        indices = np.hstack([time_idx for time_idx, space_idx in zip(self.time_idx_exp, self.space_group_idx) if space_idx == i]).tolist()\n",
    "        return lats_in_space_group, lons_in_space_group, indices\n",
    "\n",
    "    def map_match(self):\n",
    "        \"\"\"\n",
    "        CALLED BY GET_POINTS_INFO\n",
    "\n",
    "        For each of the k space groups:\n",
    "            get all points in that group, \n",
    "            map match all points using that road network\n",
    "        Return the matching edges and distance from edge for each point\n",
    "            in sorted order (sorted like original df: by traj_id and timestamp)\n",
    "        \"\"\"\n",
    "        #TODO maybe rewrite with zip\n",
    "        edges = []\n",
    "        distances = []\n",
    "        indices = []    # original point indices in order of space group\n",
    "        for i in range(self.k):\n",
    "\n",
    "            Y, X, all_t_idx_for_s = self.get_all_space_group_points(i)\n",
    "            G = self.get_road_network(self.space_group_mbrs[i])\n",
    "            e, d = ox.distance.nearest_edges(G, X, Y, return_dist=True)\n",
    "            edges.append(e)\n",
    "            distances.append(d)\n",
    "            indices.append(all_t_idx_for_s)\n",
    "\n",
    "        edges_list = np.hstack(edges).tolist()\n",
    "        distance_list = np.hstack(distances).tolist()\n",
    "        indices_list = np.hstack(indices).tolist()\n",
    "\n",
    "        paired_e = list(zip(indices_list, edges_list))\n",
    "        sorted_edges = [value for _, value in paired_e]\n",
    "\n",
    "        paired_d = list(zip(indices_list, distance_list))\n",
    "        sorted_distances = [value for _, value in paired_d]\n",
    "\n",
    "        return sorted_edges, sorted_distances\n",
    "    \n",
    "    def get_point_info(self):\n",
    "        \"\"\"\n",
    "        Return an np array with all the points in df \n",
    "            ordered by their trajectory ids and timestamp.\n",
    "\n",
    "            Currently array only has trajector id, speed, edge, \n",
    "            and distance from edge of each point\n",
    "        \"\"\"\n",
    "        # edges, distances = self.map_match()\n",
    "        # base_df = np.stack([self.traj_ids, self.speeds, edges, distances]).transpose()\n",
    "        # return base_df\n",
    "\n",
    "        return np.stack([self.traj_ids, self.speeds]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8addd290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time group index: [7, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47, 49, 62, 75, 86, 115, 116, 117]\n",
      "\n",
      "time index expanded: [array([0, 1, 2, 3, 4, 5, 6]), array([ 7,  8,  9, 10, 11, 12, 13]), array([14, 15, 16]), array([17, 18, 19]), array([20, 21, 22]), array([23, 24, 25]), array([26, 27, 28]), array([29, 30, 31]), array([32, 33, 34]), array([35, 36, 37]), array([38, 39, 40]), array([41, 42, 43]), array([44, 45, 46]), array([47, 48]), array([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]), array([62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]), array([75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85]), array([ 86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "        99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "       112, 113, 114]), array([115]), array([116]), array([117, 118, 119])]\n",
      "\n",
      "space group MBRs: [(np.float64(4.0), np.float64(2.0), np.float64(10.0), np.float64(5.0)), (np.float64(-2.0), np.float64(0.1), np.float64(5.0), np.float64(6.0)), (np.float64(2.0), np.float64(-2.5), np.float64(6.0), np.float64(2.0)), (np.float64(-5.0), np.float64(-2.0), np.float64(0.1), np.float64(2.0))]\n",
      "\n",
      "space group index: [0 0 0 0 0 0 0 0 1 2 2 1 3 3 1 1 1 1 2 2 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "partition = DataPartition(df=df)\n",
    "\n",
    "partition.print_group_indices()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa8fcc",
   "metadata": {},
   "source": [
    "Notes for *data_partition_test.csv*\n",
    "\n",
    "**traj_id a**\n",
    "* 16 total points\n",
    "* timestamps go up by 20 seconds --> time group indices [(0,7), (7,16), (16,18)] time group lat split [3.5, 4.9]\n",
    "* lat/long go up continuously\n",
    "\n",
    "**traj_id b**\n",
    "* 32 total points\n",
    "* timestamps go up by 1 minute --> time group indices [(16,19), (19,22), (22,25), (25,28), (28,31), (31, 34), (34, 37), (37, 40), (40,43), (43, 46), (46, 47)]\n",
    "* lat/long go up and down, have negative values\n",
    "\n",
    "**traj_id c**\n",
    "* 37 total points\n",
    "* timestamps go up by 10 seconds --> time group indices should be equally spaced apart by 13 (12?) lat/long splits [(1,0.7), (5,0) ]\n",
    "\n",
    "**traj_id d**\n",
    "* 29 total points\n",
    "* timestamps go up by 1 second --> time group indices are one interval\n",
    "\n",
    "**traj_id e**\n",
    "* 6 total points\n",
    "* timestamps go up by more than 2 seconds except second to last one, should be 4 time groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5d9a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = partition.get_point_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "468c9717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['a', '0.014'],\n",
       "       ['a', '0.021'],\n",
       "       ['a', '0.021'],\n",
       "       ['a', '0.011'],\n",
       "       ['a', '0.05'],\n",
       "       ['a', '0.014'],\n",
       "       ['a', '0.018000001'],\n",
       "       ['a', '0.0425'],\n",
       "       ['a', '0.011'],\n",
       "       ['a', '0.05'],\n",
       "       ['a', '0.014'],\n",
       "       ['a', '0.021'],\n",
       "       ['a', '0.021'],\n",
       "       ['a', '0.011'],\n",
       "       ['a', '0.05'],\n",
       "       ['a', '0.05'],\n",
       "       ['b', '0.0046666665'],\n",
       "       ['b', '0.0069999998'],\n",
       "       ['b', '0.0069999998'],\n",
       "       ['b', '0.0036666666'],\n",
       "       ['b', '0.016666668'],\n",
       "       ['b', '0.0046666665'],\n",
       "       ['b', '0.006'],\n",
       "       ['b', '0.014166667'],\n",
       "       ['b', '0.0036666666'],\n",
       "       ['b', '0.016666668'],\n",
       "       ['b', '0.0046666665'],\n",
       "       ['b', '0.0069999998'],\n",
       "       ['b', '0.0069999998'],\n",
       "       ['b', '0.0036666666'],\n",
       "       ['b', '0.016666668'],\n",
       "       ['b', '0.17950001'],\n",
       "       ['b', '0.033333335'],\n",
       "       ['b', '0.016666668'],\n",
       "       ['b', '0.016666668'],\n",
       "       ['b', '0.016666668'],\n",
       "       ['b', '0.016666668'],\n",
       "       ['b', '0.016666668'],\n",
       "       ['b', '0.037333332'],\n",
       "       ['b', '0.037333332'],\n",
       "       ['b', '0.037333332'],\n",
       "       ['b', '0.074499995'],\n",
       "       ['b', '0.05'],\n",
       "       ['b', '0.016666668'],\n",
       "       ['b', '0.0235'],\n",
       "       ['b', '0.016666668'],\n",
       "       ['b', '0.037333332'],\n",
       "       ['b', '0.037333332'],\n",
       "       ['c', '0.014'],\n",
       "       ['c', '0.014'],\n",
       "       ['c', '0.014'],\n",
       "       ['c', '0.014'],\n",
       "       ['c', '0.014'],\n",
       "       ['c', '0.014'],\n",
       "       ['c', '0.014'],\n",
       "       ['c', '0.014'],\n",
       "       ['c', '0.014'],\n",
       "       ['c', '0.01'],\n",
       "       ['c', '0.01'],\n",
       "       ['c', '0.01'],\n",
       "       ['c', '0.01'],\n",
       "       ['c', '0.01'],\n",
       "       ['c', '0.01'],\n",
       "       ['c', '0.01'],\n",
       "       ['c', '0.01'],\n",
       "       ['c', '0.01'],\n",
       "       ['c', '0.01'],\n",
       "       ['c', '0.01'],\n",
       "       ['c', '0.05'],\n",
       "       ['c', '0.05'],\n",
       "       ['c', '0.014'],\n",
       "       ['c', '0.091000006'],\n",
       "       ['c', '0.103999995'],\n",
       "       ['c', '0.103999995'],\n",
       "       ['c', '0.1'],\n",
       "       ['c', '0.036000002'],\n",
       "       ['c', '0.028'],\n",
       "       ['c', '0.108'],\n",
       "       ['c', '0.112'],\n",
       "       ['c', '0.044999998'],\n",
       "       ['c', '0.022'],\n",
       "       ['c', '0.042'],\n",
       "       ['c', '0.01'],\n",
       "       ['c', '0.0'],\n",
       "       ['c', '0.0'],\n",
       "       ['d', '0.28'],\n",
       "       ['d', '0.98'],\n",
       "       ['d', '1.12'],\n",
       "       ['d', '0.45'],\n",
       "       ['d', '0.92'],\n",
       "       ['d', '0.42'],\n",
       "       ['d', '0.1'],\n",
       "       ['d', '0.0'],\n",
       "       ['d', '0.07'],\n",
       "       ['d', '0.58'],\n",
       "       ['d', '0.28'],\n",
       "       ['d', '0.98'],\n",
       "       ['d', '1.12'],\n",
       "       ['d', '0.45'],\n",
       "       ['d', '0.92'],\n",
       "       ['d', '0.42'],\n",
       "       ['d', '0.1'],\n",
       "       ['d', '0.05'],\n",
       "       ['d', '0.64'],\n",
       "       ['d', '2.04'],\n",
       "       ['d', '0.28'],\n",
       "       ['d', '0.61'],\n",
       "       ['d', '2.06'],\n",
       "       ['d', '0.45'],\n",
       "       ['d', '0.22'],\n",
       "       ['d', '0.42'],\n",
       "       ['d', '0.1'],\n",
       "       ['d', '0.2'],\n",
       "       ['d', '0.2'],\n",
       "       ['e', '0.02176923'],\n",
       "       ['e', '0.008294118'],\n",
       "       ['e', '0.007724138'],\n",
       "       ['e', '0.013043478'],\n",
       "       ['e', '0.006666667'],\n",
       "       ['e', '0.006666667']], dtype='<U32')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a1bb4b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>e</td>\n",
       "      <td>0.008294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>e</td>\n",
       "      <td>0.007724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>e</td>\n",
       "      <td>0.013043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>e</td>\n",
       "      <td>0.006666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>e</td>\n",
       "      <td>0.006666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0            1\n",
       "0    a        0.014\n",
       "1    a        0.021\n",
       "2    a        0.021\n",
       "3    a        0.011\n",
       "4    a         0.05\n",
       "..  ..          ...\n",
       "115  e  0.008294118\n",
       "116  e  0.007724138\n",
       "117  e  0.013043478\n",
       "118  e  0.006666667\n",
       "119  e  0.006666667\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_df = pd.DataFrame(points)\n",
    "points_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapedia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
