{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13dcfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_lat = [0.001159, 0.0011448, 0.00115999987, 0.001140, 0.001129999, -0.001112, -0.00113983, -0.001118223, -0.00112982374]\n",
    "add_to_lon = [-0.00125, -0.001259, -0.0011154302, -0.00113, -0.00129009, -0.001011, -0.00128245, -0.000982847, -0.00122559009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89fe024a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",-122.47193407787,37.72119992213\n",
      ",-122.47078927787,37.722344722129996\n",
      ",-122.469629278,37.723504721999994\n",
      ",-122.46848927799999,37.724644721999994\n",
      ",-122.467359279,37.72577472099999\n",
      ",-122.468471279,37.724662720999994\n",
      ",-122.469611109,37.723522890999995\n",
      ",-122.470729332,37.722404667999996\n",
      ",-122.47185915574,37.721274844259995\n"
     ]
    }
   ],
   "source": [
    "prev_lat = -122.47309307787\n",
    "prev_lon = 37.720040922129996\n",
    "for i, j in zip(add_to_lat, add_to_lon):\n",
    "    prev_lat = prev_lat + i\n",
    "    prev_lon = prev_lon + i\n",
    "    print(f\",{prev_lat},{prev_lon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30806da0",
   "metadata": {},
   "source": [
    "# Test DataPartition Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e36ac00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traj_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:31:20</td>\n",
       "      <td>-122.474327</td>\n",
       "      <td>37.718807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:31:40</td>\n",
       "      <td>-122.473167</td>\n",
       "      <td>37.717556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:32:00</td>\n",
       "      <td>-122.473168</td>\n",
       "      <td>37.719966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:32:20</td>\n",
       "      <td>-122.472023</td>\n",
       "      <td>37.721111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:32:40</td>\n",
       "      <td>-122.470863</td>\n",
       "      <td>37.722271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  traj_id            timestamp   longitude   latitude\n",
       "0  0_10-0  2021-01-01 07:31:20 -122.474327  37.718807\n",
       "1  0_10-0  2021-01-01 07:31:40 -122.473167  37.717556\n",
       "2  0_10-0  2021-01-01 07:32:00 -122.473168  37.719966\n",
       "3  0_10-0  2021-01-01 07:32:20 -122.472023  37.721111\n",
       "4  0_10-0  2021-01-01 07:32:40 -122.470863  37.722271"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/bean/Documents/Doctorate/1Research/MapMetadata/mapmetadata/testing/test_osmnx.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e8776c",
   "metadata": {},
   "source": [
    "CODE FROM AUG 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "import osmnx as ox\n",
    "\n",
    "class DataPartition:\n",
    "    def __init__(self, df):\n",
    "\n",
    "        # CONFIGS\n",
    "        self.max_time_diff = pd.Timedelta(minutes=2)\n",
    "        self.k = 4\n",
    "        self.network_type = 'drive'\n",
    "        self.buffer = 0.0005    # 50m buffer\n",
    "        self.round_to = 6\n",
    "\n",
    "        # DATASET\n",
    "        self.traj_ids = df['traj_id'].to_list()\n",
    "        self.timestamps = self.get_timestamp_list(col=df['timestamp'])\n",
    "        self.latitudes = df['latitude'].to_list()\n",
    "        self.longitudes = df['longitude'].to_list()\n",
    "\n",
    "        self.num_points = len(df)\n",
    "\n",
    "        # INDEXES\n",
    "        self.time_group_idx, self.time_idx_exp, self.speeds = self.get_time_group_idx()\n",
    "        self.space_group_mbrs, self.space_group_idx = self.get_space_groups()\n",
    "\n",
    "        # DATA SUBSETS\n",
    "        self.lats_in_time_groups = np.split(self.latitudes, self.time_group_idx)\n",
    "        self.lons_in_time_groups = np.split(self.longitudes, self.time_group_idx)\n",
    "\n",
    "    def print_group_indices(self):\n",
    "\n",
    "        print(f\"time group index: {self.time_group_idx}\\n\")\n",
    "        print(f\"time index expanded: {self.time_idx_exp}\\n\")\n",
    "        print(f\"space group MBRs: {self.space_group_mbrs}\\n\")\n",
    "        print(f\"space group index: {self.space_group_idx}\\n\")\n",
    "\n",
    "        return\n",
    "\n",
    "    def get_timestamp_list(self, col):\n",
    "        \"\"\"Convert timestamps to datetime objects\"\"\"\n",
    "        dt = pd.to_datetime(col, errors = 'coerce')\n",
    "        return dt.to_list()\n",
    "\n",
    "    def get_time_group_idx(self):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "            List of index intervals defining each time group\n",
    "                All points in a time group are within the self.max_time_diff time difference\n",
    "                All points in a time group are from the same trajectory\n",
    "            Estimated speed at each point\n",
    "                The last two points are given the same speed\n",
    "        \"\"\"\n",
    "        time_group_intervals = []\n",
    "        time_intervals_expanded = []\n",
    "        time_diff = []\n",
    "        dist_diff = []\n",
    "        s = 0\n",
    "        group_time_diff = pd.Timedelta(minutes=0)\n",
    "        prev_id = self.traj_ids[0]\n",
    "        prev_lat = self.latitudes[0]\n",
    "        prev_lon = self.longitudes[0]\n",
    "        prev_timestamp = self.timestamps[0]\n",
    "\n",
    "        for i in range(1, (self.num_points-1)):\n",
    "\n",
    "            cur_id = self.traj_ids[i]\n",
    "            cur_lat = self.latitudes[i]\n",
    "            cur_lon = self.longitudes[i]\n",
    "            cur_timestamp = self.timestamps[i]\n",
    "\n",
    "            if cur_id == prev_id:\n",
    "                time_diff.append((cur_timestamp - prev_timestamp).total_seconds())\n",
    "                dist_diff.append(round(np.linalg.norm(np.array([cur_lon, cur_lat], dtype=np.float32) \n",
    "                                                      - np.array([prev_lon, prev_lat], dtype=np.float32)), \n",
    "                                       self.round_to))\n",
    "                # print(f\"TIME D \\t{(cur_timestamp - prev_timestamp).total_seconds()}\")\n",
    "                # print(f\"DIST D \\t{}\")\n",
    "                group_time_diff = cur_timestamp - self.timestamps[s]\n",
    "                if (group_time_diff > self.max_time_diff):\n",
    "                    time_group_intervals.append((s,i))\n",
    "                    time_intervals_expanded.append(np.arange(s,i))\n",
    "                    s = i\n",
    "            else:\n",
    "                # last two points of prev trajectory get same speed\n",
    "                time_diff.append(time_diff[-1])\n",
    "                dist_diff.append(dist_diff[-1])\n",
    "                prev_id = cur_id\n",
    "            \n",
    "            prev_lat = cur_lat\n",
    "            prev_lon = cur_lon\n",
    "            prev_timestamp = cur_timestamp\n",
    "\n",
    "        # last index - check if ids of last two points are the same, add correct ids to lists\n",
    "        last_i = self.num_points - 1    # == i + 1\n",
    "        cur_id = self.traj_ids[last_i]\n",
    "\n",
    "        if cur_id != prev_id:   # corner case - last point not in same trajectory as penultimate point\n",
    "            # add last group from loop\n",
    "            time_group_intervals.append((s, i))\n",
    "            time_intervals_expanded.append(np.arange(s, last_i))    # need last_i == i + 1 because we want [s, i]\n",
    "            time_diff.append(time_diff[-1])\n",
    "            dist_diff.append(dist_diff[-1])\n",
    "\n",
    "            # add last point\n",
    "            time_group_intervals.append(last_i, last_i)\n",
    "            time_intervals_expanded.append(np.arange(last_i, self.num_points))\n",
    "            time_diff.append(None)\n",
    "            dist_diff.append(None)\n",
    "\n",
    "        else:   # standard case - last point in same trajectory as penultimate point\n",
    "            time_group_intervals.append((s, last_i))\n",
    "            time_intervals_expanded.append(np.arange(s, self.num_points))\n",
    "\n",
    "            cur_lat = self.latitudes[last_i]\n",
    "            cur_lon = self.longitudes[last_i]\n",
    "            time_diff.append((self.timestamps[last_i] - self.timestamps[i]).total_seconds())\n",
    "            dist_diff.append(round(np.linalg.norm(np.array([cur_lon, cur_lat], dtype=np.float32) \n",
    "                                                  - np.array([prev_lon, prev_lat], dtype=np.float32)), \n",
    "                                   self.round_to))\n",
    "\n",
    "        indices = [end for _, end in time_group_intervals[:-1]]  #TODO: make this the time_group_idx if we only need these vals   \n",
    "\n",
    "        dt = [d/t for d, t in zip(dist_diff,time_diff)]\n",
    "        dt.append(dt[-1])   # last two points have the same value\n",
    "\n",
    "        return indices, time_intervals_expanded, dt\n",
    "    \n",
    "    def get_extrema(self):\n",
    "        \"\"\"\n",
    "        CALLED BY GET_SPACE_GROUPS\n",
    "\n",
    "        Get the min/max lat/long of the first and last points in a time group\n",
    "        Return [min lat, max lat] , [min_long, max_long]\n",
    "        \"\"\"\n",
    "        # indices = [end for _, end in self.time_group_idx[:-1]]  #TODO: make this the time_group_idx if we only need these vals   \n",
    "\n",
    "        # [time group 1 [first point lat/lon, last point lat/lon], time group 2 [ first point, last point], ...]\n",
    "        first_last_lats = np.matrix([[l[0], l[-1]] for l in np.split(self.latitudes, self.time_group_idx)])\n",
    "        first_last_lons = np.matrix([[l[0], l[-1]] for l in np.split(self.longitudes, self.time_group_idx)])\n",
    "        \n",
    "        sorted_lats = np.asarray(np.sort(first_last_lats, axis=1))\n",
    "        sorted_lons = np.asarray(np.sort(first_last_lons, axis=1))\n",
    "\n",
    "        return sorted_lats, sorted_lons\n",
    "\n",
    "    def get_bbox(self, lat, lon):\n",
    "        \"\"\"\n",
    "        CALLED BY GET_SPACE_GROUPS\n",
    "\n",
    "        Given a space group label, get all the lat/lon values [time group values] that are in that space group\n",
    "            (lat/lon are list of [min val, max val] of each time group, and you mask by space group label i)\n",
    "        Return (min_long, min_lat, max_long, max_lat) == (left, bottom, right, top)\n",
    "        \"\"\"\n",
    "        w_min_lon = min(lon) - self.buffer\n",
    "        s_min_lat = min(lat) - self.buffer\n",
    "        e_max_lon = max(lon) + self.buffer\n",
    "        n_max_lat = max(lat) + self.buffer\n",
    "        return (w_min_lon, s_min_lat, e_max_lon, n_max_lat)\n",
    "\n",
    "    def get_space_groups(self):\n",
    "        \"\"\"\n",
    "        NOTES:  Number of space groups is the number of road networks\n",
    "                We want to get the smallest number of road networks that are small enough\n",
    "                to make map matching fast, so we cluster all the MBRs into k groups\n",
    "\n",
    "        Return:\n",
    "            space_groups: mbr of each space group (there are k groups)\n",
    "                mbr = [min_long, min_lat, max_long, max_lat] == [left, bottom, right, top]\n",
    "            labels: list of corresponding space group index for each time group\n",
    "                index is the index of the space group each time group belongs in\n",
    "        \"\"\"\n",
    "        sorted_lats, sorted_lons = self.get_extrema()\n",
    "        mbrs = np.hstack([sorted_lats, sorted_lons])\n",
    "\n",
    "        centroids = [( (x1+x2)/2, (y1+y2)/2 ) for y1, y2, x1, x2 in mbrs]\n",
    "        kmeans = KMeans(n_clusters = self.k).fit(centroids)\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        space_groups = []\n",
    "        for i in range(self.k):\n",
    "            space_groups.append(self.get_bbox(lat=sorted_lats[i].tolist(), lon=sorted_lons[i].tolist()))\n",
    "\n",
    "        return space_groups, labels\n",
    "    \n",
    "    def get_road_network(self, mbr):\n",
    "        \"\"\"\n",
    "        CALLED BY MAP_MATCH\n",
    "\n",
    "        Return OSM road network within the given space group mbr\n",
    "        \"\"\"\n",
    "        g = ox.graph_from_bbox(bbox=mbr, network_type=self.network_type, \n",
    "                               retain_all=True, truncate_by_edge=True, simplify=False)\n",
    "        # return ox.projection.project_graph(g)\n",
    "        return g\n",
    "\n",
    "    def get_all_space_group_points(self, i):\n",
    "        \"\"\"\n",
    "        CALLED BY MAP_MATCH\n",
    "\n",
    "        Given a space group label\n",
    "        Return all the point coordinates that correspond to that space group as a list\n",
    "            need to return lat and long separately because osm.nearest_edges takes them separately\n",
    "            if it is no longer needed, can do them all at once:\n",
    "                points_in_space_group = [time_group for time_group, space_idx in zip(self.points_in_time_groups, self.space_group_idx) if space_idx == i]\n",
    "                return np.vstack(points_in_space_group).tolist()\n",
    "        \"\"\"\n",
    "        lats_in_space_group = np.hstack([time_group for time_group, space_idx in zip(self.lats_in_time_groups, self.space_group_idx) if space_idx == i]).tolist()\n",
    "        lons_in_space_group = np.hstack([time_group for time_group, space_idx in zip(self.lons_in_time_groups, self.space_group_idx) if space_idx == i]).tolist()\n",
    "        indices = np.hstack([time_idx for time_idx, space_idx in zip(self.time_idx_exp, self.space_group_idx) if space_idx == i]).tolist()\n",
    "        return lats_in_space_group, lons_in_space_group, indices\n",
    "\n",
    "    def map_match(self):\n",
    "        \"\"\"\n",
    "        CALLED BY GET_POINTS_INFO\n",
    "\n",
    "        For each of the k space groups:\n",
    "            get all points in that group, \n",
    "            map match all points using that road network\n",
    "        Return the matching edges and distance from edge for each point\n",
    "            in sorted order (sorted like original df: by traj_id and timestamp)\n",
    "        \"\"\"\n",
    "        #TODO maybe rewrite with zip\n",
    "        edges = []\n",
    "        distances = []\n",
    "        u_distances = []\n",
    "        v_distances = []\n",
    "        indices = []    # original point indices in order of space group\n",
    "        for i in range(self.k):\n",
    "\n",
    "            Y, X, all_t_idx_for_s = self.get_all_space_group_points(i)\n",
    "            G = self.get_road_network(self.space_group_mbrs[i])\n",
    "            e, d = ox.distance.nearest_edges(G, X, Y, return_dist=True)\n",
    "\n",
    "            u_dist = [round(np.linalg.norm(np.array([G.nodes[row[0]]['x'], G.nodes[row[0]]['y']]) \n",
    "                                           - np.array([x, y])), \n",
    "                            self.round_to) for row, x, y in zip(e, X, Y)]\n",
    "            \n",
    "            v_dist = [round(np.linalg.norm(np.array([G.nodes[row[1]]['x'], G.nodes[row[1]]['y']]) \n",
    "                                           - np.array([x, y])), \n",
    "                            self.round_to) for row, x, y in zip(e, X, Y)]\n",
    "\n",
    "            edges.append(e)\n",
    "            distances.append(d)\n",
    "            u_distances.append(u_dist)\n",
    "            v_distances.append(v_dist)\n",
    "            indices.append(all_t_idx_for_s)\n",
    "\n",
    "        edges_list = np.hstack(edges).tolist()\n",
    "        distance_list = np.hstack(distances).tolist()\n",
    "        u_dist_list = np.concatenate(u_distances).tolist()\n",
    "        v_dist_list = np.concatenate(v_distances).tolist()\n",
    "        indices_list = np.hstack(indices).tolist()\n",
    "\n",
    "\n",
    "        paired_e = list(zip(indices_list, edges_list))\n",
    "        sorted_edges = [value for _, value in paired_e]\n",
    "\n",
    "        paired_d = list(zip(indices_list, distance_list))\n",
    "        sorted_distances = [value for _, value in paired_d]\n",
    "\n",
    "        paired_u_dists = list(zip(indices_list, u_dist_list))\n",
    "        sorted_u_dists = [value for _, value in paired_u_dists]\n",
    "\n",
    "        paired_v_dists = list(zip(indices_list, v_dist_list))\n",
    "        sorted_v_dists = [value for _, value in paired_v_dists]\n",
    "\n",
    "        return sorted_edges, sorted_distances, sorted_u_dists, sorted_v_dists\n",
    "    \n",
    "    def get_point_info(self):\n",
    "        \"\"\"\n",
    "        Return an np array with all the points in df \n",
    "            ordered by their trajectory ids and timestamp.\n",
    "\n",
    "            Currently array only has trajector id, speed, edge, \n",
    "            and distance from edge of each point\n",
    "        \"\"\"\n",
    "        edges, distances, u_dist, v_dist = self.map_match()\n",
    "        s, d, k = zip(*edges)\n",
    "        # base_df = np.stack([self.traj_ids, self.latitudes, self.longitudes, self.speeds, s, d, k, u_dist, v_dist, distances]).transpose()\n",
    "        base_df = np.stack([self.traj_ids, self.timestamps, self.speeds, s, d, k, u_dist, v_dist, distances]).transpose()\n",
    "        return base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc3751",
   "metadata": {},
   "source": [
    "CODE FROM AUG 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "54ad7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "import osmnx as ox\n",
    "\n",
    "class DataPartition:\n",
    "    def __init__(self, df):\n",
    "\n",
    "        # CONFIGS\n",
    "        self.max_time_diff = pd.Timedelta(minutes=2)\n",
    "        self.k = 4\n",
    "        self.network_type = 'drive'\n",
    "        self.buffer = 0.0005    # 50m buffer\n",
    "        self.round_to = 6\n",
    "\n",
    "        # DATASET\n",
    "        self.traj_ids = df['traj_id'].to_list()\n",
    "        self.timestamps = self.get_timestamp_list(col=df['timestamp'])\n",
    "        self.latitudes = df['latitude'].to_list()\n",
    "        self.longitudes = df['longitude'].to_list()\n",
    "\n",
    "        self.num_points = len(df)\n",
    "\n",
    "        # INDEXES\n",
    "        self.time_group_idx, self.time_idx_exp, self.speeds = self.get_time_group_idx()\n",
    "        self.space_group_mbrs, self.space_group_idx = self.get_space_groups()\n",
    "\n",
    "        # DATA SUBSETS\n",
    "        self.lats_in_time_groups = np.split(self.latitudes, self.time_group_idx)\n",
    "        self.lons_in_time_groups = np.split(self.longitudes, self.time_group_idx)\n",
    "\n",
    "    def print_group_indices(self):\n",
    "\n",
    "        print(f\"time group index: {self.time_group_idx}\\n\")\n",
    "        print(f\"time index expanded: {self.time_idx_exp}\\n\")\n",
    "        print(f\"space group MBRs: {self.space_group_mbrs}\\n\")\n",
    "        print(f\"space group index: {self.space_group_idx}\\n\")\n",
    "\n",
    "        return\n",
    "\n",
    "    def get_timestamp_list(self, col):\n",
    "        \"\"\"Convert timestamps to datetime objects\"\"\"\n",
    "        dt = pd.to_datetime(col, errors = 'coerce')\n",
    "        return dt.to_list()\n",
    "\n",
    "    def dist_btwn_points(self, lat1, lon1, lat2, lon2):\n",
    "        \"\"\"Returns distance in km\"\"\"\n",
    "        d = ox.distance.great_circle(lat1=lat1, lon1=lon1, lat2=lat2, lon2=lon2, earth_radius=6371.009)\n",
    "        return round(d, self.round_to)\n",
    "\n",
    "    def get_time_group_idx(self):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "            List of index intervals defining each time group\n",
    "                All points in a time group are within the self.max_time_diff time difference\n",
    "                All points in a time group are from the same trajectory\n",
    "            Estimated speed at each point\n",
    "                The last two points are given the same speed\n",
    "        \"\"\"\n",
    "        time_group_intervals = []\n",
    "        time_intervals_expanded = []\n",
    "        time_diff = []\n",
    "        dist_diff = []\n",
    "        s = 0\n",
    "        group_time_diff = pd.Timedelta(minutes=0)\n",
    "        prev_id = self.traj_ids[0]\n",
    "        prev_lat = self.latitudes[0]\n",
    "        prev_lon = self.longitudes[0]\n",
    "        prev_timestamp = self.timestamps[0]\n",
    "\n",
    "        def time_btwn_points(t1, t2):\n",
    "            \"\"\"Returns time in hours\"\"\"\n",
    "            d = (t2 - t1).total_seconds()\n",
    "            return round((d/3600), self.round_to)\n",
    "\n",
    "        for i in range(1, (self.num_points-1)):\n",
    "\n",
    "            cur_id = self.traj_ids[i]\n",
    "            cur_lat = self.latitudes[i]\n",
    "            cur_lon = self.longitudes[i]\n",
    "            cur_timestamp = self.timestamps[i]\n",
    "\n",
    "            if cur_id == prev_id:\n",
    "                time_diff.append(time_btwn_points(prev_timestamp, cur_timestamp))\n",
    "                dist_diff.append(self.dist_btwn_points(lat1=prev_lat, lon1=prev_lon, lat2=cur_lat, lon2=cur_lon))\n",
    "                group_time_diff = cur_timestamp - self.timestamps[s]\n",
    "                if (group_time_diff > self.max_time_diff):\n",
    "                    time_group_intervals.append((s,i))\n",
    "                    time_intervals_expanded.append(np.arange(s,i))\n",
    "                    s = i\n",
    "            else:\n",
    "                # last two points of prev trajectory get same speed\n",
    "                time_diff.append(time_diff[-1])\n",
    "                dist_diff.append(dist_diff[-1])\n",
    "                prev_id = cur_id\n",
    "            \n",
    "            prev_lat = cur_lat\n",
    "            prev_lon = cur_lon\n",
    "            prev_timestamp = cur_timestamp\n",
    "\n",
    "        # last index - check if ids of last two points are the same, add correct ids to lists\n",
    "        last_i = self.num_points - 1    # == i + 1\n",
    "        cur_id = self.traj_ids[last_i]\n",
    "\n",
    "        if cur_id != prev_id:   # corner case - last point not in same trajectory as penultimate point\n",
    "            # add last group from loop\n",
    "            time_group_intervals.append((s, i))\n",
    "            time_intervals_expanded.append(np.arange(s, last_i))    # need last_i == i + 1 because we want [s, i]\n",
    "            time_diff.append(time_diff[-1])\n",
    "            dist_diff.append(dist_diff[-1])\n",
    "\n",
    "            # add last point\n",
    "            time_group_intervals.append(last_i, last_i)\n",
    "            time_intervals_expanded.append(np.arange(last_i, self.num_points))\n",
    "            time_diff.append(None)\n",
    "            dist_diff.append(None)\n",
    "\n",
    "        else:   # standard case - last point in same trajectory as penultimate point\n",
    "            time_group_intervals.append((s, last_i))\n",
    "            time_intervals_expanded.append(np.arange(s, self.num_points))\n",
    "\n",
    "            cur_lat = self.latitudes[last_i]\n",
    "            cur_lon = self.longitudes[last_i]\n",
    "            time_diff.append(time_btwn_points(self.timestamps[i], self.timestamps[last_i]))\n",
    "            dist_diff.append(self.dist_btwn_points(lat1=prev_lat, lon1=prev_lon, lat2=cur_lat, lon2=cur_lon))\n",
    "\n",
    "        indices = [end for _, end in time_group_intervals[:-1]]  #TODO: make this the time_group_idx if we only need these vals   \n",
    "\n",
    "        dt = [d/t for d, t in zip(dist_diff,time_diff)]\n",
    "        dt.append(dt[-1])   # last two points have the same value\n",
    "\n",
    "        return indices, time_intervals_expanded, dt\n",
    "    \n",
    "    def get_extrema(self):\n",
    "        \"\"\"\n",
    "        CALLED BY GET_SPACE_GROUPS\n",
    "\n",
    "        Get the min/max lat/long of the first and last points in a time group\n",
    "        Return [min lat, max lat] , [min_long, max_long]\n",
    "        \"\"\"\n",
    "        # indices = [end for _, end in self.time_group_idx[:-1]]  #TODO: make this the time_group_idx if we only need these vals   \n",
    "\n",
    "        # [time group 1 [first point lat/lon, last point lat/lon], time group 2 [ first point, last point], ...]\n",
    "        first_last_lats = np.matrix([[l[0], l[-1]] for l in np.split(self.latitudes, self.time_group_idx)])\n",
    "        first_last_lons = np.matrix([[l[0], l[-1]] for l in np.split(self.longitudes, self.time_group_idx)])\n",
    "        \n",
    "        sorted_lats = np.asarray(np.sort(first_last_lats, axis=1))\n",
    "        sorted_lons = np.asarray(np.sort(first_last_lons, axis=1))\n",
    "\n",
    "        return sorted_lats, sorted_lons\n",
    "\n",
    "    def get_bbox(self, lat, lon):\n",
    "        \"\"\"\n",
    "        CALLED BY GET_SPACE_GROUPS\n",
    "\n",
    "        Given a space group label, get all the lat/lon values [time group values] that are in that space group\n",
    "            (lat/lon are list of [min val, max val] of each time group, and you mask by space group label i)\n",
    "        Return (min_long, min_lat, max_long, max_lat) == (left, bottom, right, top)\n",
    "        \"\"\"\n",
    "        w_min_lon = min(lon) - self.buffer\n",
    "        s_min_lat = min(lat) - self.buffer\n",
    "        e_max_lon = max(lon) + self.buffer\n",
    "        n_max_lat = max(lat) + self.buffer\n",
    "        return (w_min_lon, s_min_lat, e_max_lon, n_max_lat)\n",
    "\n",
    "    def get_space_groups(self):\n",
    "        \"\"\"\n",
    "        NOTES:  Number of space groups is the number of road networks\n",
    "                We want to get the smallest number of road networks that are small enough\n",
    "                to make map matching fast, so we cluster all the MBRs into k groups\n",
    "\n",
    "        Return:\n",
    "            space_groups: mbr of each space group (there are k groups)\n",
    "                mbr = [min_long, min_lat, max_long, max_lat] == [left, bottom, right, top]\n",
    "            labels: list of corresponding space group index for each time group\n",
    "                index is the index of the space group each time group belongs in\n",
    "        \"\"\"\n",
    "        sorted_lats, sorted_lons = self.get_extrema()\n",
    "        mbrs = np.hstack([sorted_lats, sorted_lons])\n",
    "\n",
    "        centroids = [( (x1+x2)/2, (y1+y2)/2 ) for y1, y2, x1, x2 in mbrs]\n",
    "        kmeans = KMeans(n_clusters = self.k).fit(centroids)\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        space_groups = []\n",
    "        for i in range(self.k):\n",
    "            space_groups.append(self.get_bbox(lat=sorted_lats[i].tolist(), lon=sorted_lons[i].tolist()))\n",
    "\n",
    "        return space_groups, labels\n",
    "    \n",
    "    def get_road_network(self, mbr):\n",
    "        \"\"\"\n",
    "        CALLED BY MAP_MATCH\n",
    "\n",
    "        Return OSM road network within the given space group mbr\n",
    "        \"\"\"\n",
    "        g = ox.graph_from_bbox(bbox=mbr, network_type=self.network_type, \n",
    "                               retain_all=True, truncate_by_edge=True, simplify=False)\n",
    "        # return ox.projection.project_graph(g)\n",
    "        return g\n",
    "\n",
    "    def get_all_space_group_points(self, i):\n",
    "        \"\"\"\n",
    "        CALLED BY MAP_MATCH\n",
    "\n",
    "        Given a space group label\n",
    "        Return all the point coordinates that correspond to that space group as a list\n",
    "            need to return lat and long separately because osm.nearest_edges takes them separately\n",
    "            if it is no longer needed, can do them all at once:\n",
    "                points_in_space_group = [time_group for time_group, space_idx in zip(self.points_in_time_groups, self.space_group_idx) if space_idx == i]\n",
    "                return np.vstack(points_in_space_group).tolist()\n",
    "        \"\"\"\n",
    "        lats_in_space_group = np.hstack([time_group for time_group, space_idx in zip(self.lats_in_time_groups, self.space_group_idx) if space_idx == i]).tolist()\n",
    "        lons_in_space_group = np.hstack([time_group for time_group, space_idx in zip(self.lons_in_time_groups, self.space_group_idx) if space_idx == i]).tolist()\n",
    "        indices = np.hstack([time_idx for time_idx, space_idx in zip(self.time_idx_exp, self.space_group_idx) if space_idx == i]).tolist()\n",
    "        return lats_in_space_group, lons_in_space_group, indices\n",
    "\n",
    "    def map_match(self):\n",
    "        \"\"\"\n",
    "        CALLED BY GET_POINTS_INFO\n",
    "\n",
    "        For each of the k space groups:\n",
    "            get all points in that group, \n",
    "            map match all points using that road network\n",
    "        Return the matching edges and distance from edge for each point\n",
    "            in sorted order (sorted like original df: by traj_id and timestamp)\n",
    "        \"\"\"\n",
    "        #TODO maybe rewrite with zip\n",
    "        edges = []\n",
    "        distances = []\n",
    "        u_distances = []\n",
    "        v_distances = []\n",
    "        osmids = []\n",
    "        indices = []    # original point indices in order of space group\n",
    "\n",
    "        for i in range(self.k):\n",
    "\n",
    "            Y, X, all_t_idx_for_s = self.get_all_space_group_points(i)\n",
    "            G = self.get_road_network(self.space_group_mbrs[i])\n",
    "            e, d = ox.distance.nearest_edges(G, X, Y, return_dist=True)\n",
    "\n",
    "            u_dist = [(self.dist_btwn_points(lat1=y, lon1=x, lat2=G.nodes[row[0]]['y'], lon2=G.nodes[row[0]]['x'])) for row, x, y in zip(e, X, Y)]\n",
    "            v_dist = [(self.dist_btwn_points(lat1=y, lon1=x, lat2=G.nodes[row[1]]['y'], lon2=G.nodes[row[1]]['x'])) for row, x, y in zip(e, X, Y)]\n",
    "\n",
    "            e_gdfs = ox.convert.graph_to_gdfs(G, nodes=False, edges = True)\n",
    "            ids = [e_gdfs.loc[row]['osmid'] for row in e]\n",
    "\n",
    "\n",
    "            \n",
    "            # edges.loc[( 270672090,  3483658791, 0)]['osmid']\n",
    "\n",
    "\n",
    "            edges.append(e)\n",
    "            distances.append(d)\n",
    "            u_distances.append(u_dist)\n",
    "            v_distances.append(v_dist)\n",
    "            osmids.append(ids)\n",
    "            indices.append(all_t_idx_for_s)\n",
    "\n",
    "        edges_list = np.hstack(edges).tolist()\n",
    "        distance_list = np.hstack(distances).tolist()\n",
    "        u_dist_list = np.concatenate(u_distances).tolist()\n",
    "        v_dist_list = np.concatenate(v_distances).tolist()\n",
    "        osmids_list = np.concatenate(osmids).tolist()\n",
    "        indices_list = np.hstack(indices).tolist()\n",
    "\n",
    "        paired_e = list(zip(indices_list, edges_list))\n",
    "        sorted_edges = [value for _, value in paired_e]\n",
    "\n",
    "        paired_d = list(zip(indices_list, distance_list))\n",
    "        sorted_distances = [value for _, value in paired_d]\n",
    "\n",
    "        paired_u_dists = list(zip(indices_list, u_dist_list))\n",
    "        sorted_u_dists = [value for _, value in paired_u_dists]\n",
    "\n",
    "        paired_v_dists = list(zip(indices_list, v_dist_list))\n",
    "        sorted_v_dists = [value for _, value in paired_v_dists]\n",
    "\n",
    "        paired_ids = list(zip(indices_list, osmids_list))\n",
    "        sorted_osmids = [value for _, value in paired_ids]\n",
    "\n",
    "        return sorted_edges, sorted_distances, sorted_u_dists, sorted_v_dists, sorted_osmids\n",
    "    \n",
    "    def get_point_info(self):\n",
    "        \"\"\"\n",
    "        Return an np array with all the points in df \n",
    "            ordered by their trajectory ids and timestamp.\n",
    "\n",
    "            Currently array only has trajector id, speed, edge, \n",
    "            and distance from edge of each point\n",
    "        \"\"\"\n",
    "        edges, distances, u_dist, v_dist, osmids = self.map_match()\n",
    "        s, d, k = zip(*edges)\n",
    "        base_df = np.stack([self.traj_ids, self.timestamps, self.speeds, osmids, s, d, k, u_dist, v_dist, distances]).transpose()\n",
    "        return base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d749651",
   "metadata": {},
   "source": [
    "AUG 3 OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "149e0b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time group index: [6, 8, 13, 18]\n",
      "\n",
      "time index expanded: [array([0, 1, 2, 3, 4, 5]), array([6, 7]), array([ 8,  9, 10, 11, 12]), array([13, 14, 15, 16, 17]), array([18, 19, 20])]\n",
      "\n",
      "space group MBRs: [(-122.474827, 37.718306999999996, -122.46922320013, 37.72391079987), (-122.47020520113, 37.72292879887, -122.46809320113, 37.72504079887), (-122.47134503113, 37.721788968869994, -122.47028927787, 37.722844722130006), (-122.470129278, 37.72300472199999, -122.469111109, 37.724022891)]\n",
      "\n",
      "space group index: [2 1 0 1 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "partition = DataPartition(df)\n",
    "partition.print_group_indices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221412cd",
   "metadata": {},
   "source": [
    "AUG 4 OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8d3e92a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time group index: [6, 8, 13, 18]\n",
      "\n",
      "time index expanded: [array([0, 1, 2, 3, 4, 5]), array([6, 7]), array([ 8,  9, 10, 11, 12]), array([13, 14, 15, 16, 17]), array([18, 19, 20])]\n",
      "\n",
      "space group MBRs: [(-122.474827, 37.718306999999996, -122.46922320013, 37.72391079987), (-122.47020520113, 37.72292879887, -122.46809320113, 37.72504079887), (-122.47134503113, 37.721788968869994, -122.47028927787, 37.722844722130006), (-122.470129278, 37.72300472199999, -122.469111109, 37.724022891)]\n",
      "\n",
      "space group index: [2 0 3 0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "partition = DataPartition(df)\n",
    "partition.print_group_indices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea1420",
   "metadata": {},
   "source": [
    "AUG 9 OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5576dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import osmnx as ox\n",
    "\n",
    "class DataPartition:\n",
    "    def __init__(self, df):\n",
    "\n",
    "        # CONFIGS\n",
    "        self.max_time_diff = pd.Timedelta(minutes=2)\n",
    "        self.k = 4\n",
    "        self.network_type = 'drive'\n",
    "        self.buffer = 0.0005    # 50m buffer\n",
    "        self.round_to = 6\n",
    "\n",
    "        # DATASET\n",
    "        self.traj_ids = df['traj_id'].to_list()\n",
    "        self.timestamps = self.get_timestamp_list(col=df['timestamp'])\n",
    "        self.latitudes = df['latitude'].to_list()\n",
    "        self.longitudes = df['longitude'].to_list()\n",
    "\n",
    "        self.num_points = len(df)\n",
    "\n",
    "        # INDEXES\n",
    "        self.time_group_idx, self.time_idx_exp, self.speeds = self.get_time_group_idx()\n",
    "        self.space_group_mbrs, self.space_group_idx = self.get_space_groups()\n",
    "\n",
    "        # DATA SUBSETS\n",
    "        self.lats_in_time_groups = np.split(self.latitudes, self.time_group_idx)\n",
    "        self.lons_in_time_groups = np.split(self.longitudes, self.time_group_idx)\n",
    "\n",
    "    def print_group_indices(self):\n",
    "\n",
    "        print(f\"time group index: {self.time_group_idx}\\n\")\n",
    "        print(f\"time index expanded: {self.time_idx_exp}\\n\")\n",
    "        print(f\"space group MBRs: {self.space_group_mbrs}\\n\")\n",
    "        print(f\"space group index: {self.space_group_idx}\\n\")\n",
    "\n",
    "        return\n",
    "\n",
    "    def get_timestamp_list(self, col):\n",
    "        \"\"\"Convert timestamps to datetime objects\"\"\"\n",
    "        dt = pd.to_datetime(col, errors = 'coerce')\n",
    "        return dt.to_list()\n",
    "\n",
    "    def dist_btwn_points(self, lat1, lon1, lat2, lon2):\n",
    "        \"\"\"Returns distance in km\"\"\"\n",
    "        d = ox.distance.great_circle(lat1=lat1, lon1=lon1, lat2=lat2, lon2=lon2, earth_radius=6371.009)\n",
    "        return round(d, self.round_to)\n",
    "\n",
    "    def get_time_group_idx(self):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "            List of index intervals defining each time group\n",
    "                All points in a time group are within the self.max_time_diff time difference\n",
    "                All points in a time group are from the same trajectory\n",
    "            Estimated speed at each point\n",
    "                The last two points are given the same speed\n",
    "        \"\"\"\n",
    "        time_group_intervals = []\n",
    "        time_intervals_expanded = []\n",
    "        time_diff = []\n",
    "        dist_diff = []\n",
    "        s = 0\n",
    "        group_time_diff = pd.Timedelta(minutes=0)\n",
    "        prev_id = self.traj_ids[0]\n",
    "        prev_lat = self.latitudes[0]\n",
    "        prev_lon = self.longitudes[0]\n",
    "        prev_timestamp = self.timestamps[0]\n",
    "\n",
    "        def time_btwn_points(t1, t2):\n",
    "            \"\"\"Returns time in hours\"\"\"\n",
    "            d = (t2 - t1).total_seconds()\n",
    "            return round((d/3600), self.round_to)\n",
    "\n",
    "        for i in range(1, (self.num_points-1)):\n",
    "\n",
    "            cur_id = self.traj_ids[i]\n",
    "            cur_lat = self.latitudes[i]\n",
    "            cur_lon = self.longitudes[i]\n",
    "            cur_timestamp = self.timestamps[i]\n",
    "\n",
    "            if cur_id == prev_id:\n",
    "                time_diff.append(time_btwn_points(prev_timestamp, cur_timestamp))\n",
    "                dist_diff.append(self.dist_btwn_points(lat1=prev_lat, lon1=prev_lon, lat2=cur_lat, lon2=cur_lon))\n",
    "                group_time_diff = cur_timestamp - self.timestamps[s]\n",
    "                if (group_time_diff > self.max_time_diff):\n",
    "                    time_group_intervals.append((s,i))\n",
    "                    time_intervals_expanded.append(np.arange(s,i))\n",
    "                    s = i\n",
    "            else:\n",
    "                # last two points of prev trajectory get same speed\n",
    "                time_diff.append(time_diff[-1])\n",
    "                dist_diff.append(dist_diff[-1])\n",
    "                prev_id = cur_id\n",
    "            \n",
    "            prev_lat = cur_lat\n",
    "            prev_lon = cur_lon\n",
    "            prev_timestamp = cur_timestamp\n",
    "\n",
    "        # last index - check if ids of last two points are the same, add correct ids to lists\n",
    "        last_i = self.num_points - 1    # == i + 1\n",
    "        cur_id = self.traj_ids[last_i]\n",
    "\n",
    "        if cur_id != prev_id:   # corner case - last point not in same trajectory as penultimate point\n",
    "            # add last group from loop\n",
    "            time_group_intervals.append((s, i))\n",
    "            time_intervals_expanded.append(np.arange(s, last_i))    # need last_i == i + 1 because we want [s, i]\n",
    "            time_diff.append(time_diff[-1])\n",
    "            dist_diff.append(dist_diff[-1])\n",
    "\n",
    "            # add last point\n",
    "            time_group_intervals.append(last_i, last_i)\n",
    "            time_intervals_expanded.append(np.arange(last_i, self.num_points))\n",
    "            time_diff.append(None)\n",
    "            dist_diff.append(None)\n",
    "\n",
    "        else:   # standard case - last point in same trajectory as penultimate point\n",
    "            time_group_intervals.append((s, last_i))\n",
    "            time_intervals_expanded.append(np.arange(s, self.num_points))\n",
    "\n",
    "            cur_lat = self.latitudes[last_i]\n",
    "            cur_lon = self.longitudes[last_i]\n",
    "            time_diff.append(time_btwn_points(self.timestamps[i], self.timestamps[last_i]))\n",
    "            dist_diff.append(self.dist_btwn_points(lat1=prev_lat, lon1=prev_lon, lat2=cur_lat, lon2=cur_lon))\n",
    "\n",
    "        indices = [end for _, end in time_group_intervals[:-1]]  #TODO: make this the time_group_idx if we only need these vals   \n",
    "\n",
    "        dt = [d/t for d, t in zip(dist_diff,time_diff)]\n",
    "        dt.append(dt[-1])   # last two points have the same value\n",
    "\n",
    "        return indices, time_intervals_expanded, dt\n",
    "    \n",
    "    def get_extrema(self):\n",
    "        \"\"\"\n",
    "        CALLED BY GET_SPACE_GROUPS\n",
    "\n",
    "        Get the min/max lat/long of the first and last points in a time group\n",
    "        Return [min lat, max lat] , [min_long, max_long]\n",
    "        \"\"\"\n",
    "        # indices = [end for _, end in self.time_group_idx[:-1]]  #TODO: make this the time_group_idx if we only need these vals   \n",
    "\n",
    "        # [time group 1 [first point lat/lon, last point lat/lon], time group 2 [ first point, last point], ...]\n",
    "        first_last_lats = np.matrix([[l[0], l[-1]] for l in np.split(self.latitudes, self.time_group_idx)])\n",
    "        first_last_lons = np.matrix([[l[0], l[-1]] for l in np.split(self.longitudes, self.time_group_idx)])\n",
    "        \n",
    "        sorted_lats = np.asarray(np.sort(first_last_lats, axis=1))\n",
    "        sorted_lons = np.asarray(np.sort(first_last_lons, axis=1))\n",
    "\n",
    "        return sorted_lats, sorted_lons\n",
    "\n",
    "    def get_bbox(self, lat, lon):\n",
    "        \"\"\"\n",
    "        CALLED BY GET_SPACE_GROUPS\n",
    "\n",
    "        Given a space group label, get all the lat/lon values [time group values] that are in that space group\n",
    "            (lat/lon are list of [min val, max val] of each time group, and you mask by space group label i)\n",
    "        Return (min_long, min_lat, max_long, max_lat) == (left, bottom, right, top)\n",
    "        \"\"\"\n",
    "        w_min_lon = min(lon) - self.buffer\n",
    "        s_min_lat = min(lat) - self.buffer\n",
    "        e_max_lon = max(lon) + self.buffer\n",
    "        n_max_lat = max(lat) + self.buffer\n",
    "        return (w_min_lon, s_min_lat, e_max_lon, n_max_lat)\n",
    "\n",
    "    def get_space_groups(self):\n",
    "        \"\"\"\n",
    "        NOTES:  Number of space groups is the number of road networks\n",
    "                We want to get the smallest number of road networks that are small enough\n",
    "                to make map matching fast, so we cluster all the MBRs into k groups\n",
    "\n",
    "        Return:\n",
    "            space_groups: mbr of each space group (there are k groups)\n",
    "                mbr = [min_long, min_lat, max_long, max_lat] == [left, bottom, right, top]\n",
    "            labels: list of corresponding space group index for each time group\n",
    "                index is the index of the space group each time group belongs in\n",
    "        \"\"\"\n",
    "        sorted_lats, sorted_lons = self.get_extrema()\n",
    "        mbrs = np.hstack([sorted_lats, sorted_lons])\n",
    "\n",
    "        centroids = [( (x1+x2)/2, (y1+y2)/2 ) for y1, y2, x1, x2 in mbrs]\n",
    "        kmeans = KMeans(n_clusters = self.k).fit(centroids)\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        space_groups = []\n",
    "        for i in range(self.k):\n",
    "            space_groups.append(self.get_bbox(lat=sorted_lats[i].tolist(), lon=sorted_lons[i].tolist()))\n",
    "\n",
    "        return space_groups, labels\n",
    "    \n",
    "    def get_road_network(self, mbr):\n",
    "        \"\"\"\n",
    "        CALLED BY MAP_MATCH\n",
    "\n",
    "        Return OSM road network within the given space group mbr\n",
    "        \"\"\"\n",
    "        g = ox.graph_from_bbox(bbox=mbr, network_type=self.network_type, \n",
    "                               retain_all=True, truncate_by_edge=True, simplify=False)\n",
    "        # return ox.projection.project_graph(g)\n",
    "        return g\n",
    "\n",
    "    def get_all_space_group_points(self, i):\n",
    "        \"\"\"\n",
    "        CALLED BY MAP_MATCH\n",
    "\n",
    "        Given a space group label\n",
    "        Return all the point coordinates that correspond to that space group as a list\n",
    "            need to return lat and long separately because osm.nearest_edges takes them separately\n",
    "            if it is no longer needed, can do them all at once:\n",
    "                points_in_space_group = [time_group for time_group, space_idx in zip(self.points_in_time_groups, self.space_group_idx) if space_idx == i]\n",
    "                return np.vstack(points_in_space_group).tolist()\n",
    "        \"\"\"\n",
    "        lats_in_space_group = np.hstack([time_group for time_group, space_idx in zip(self.lats_in_time_groups, self.space_group_idx) if space_idx == i]).tolist()\n",
    "        lons_in_space_group = np.hstack([time_group for time_group, space_idx in zip(self.lons_in_time_groups, self.space_group_idx) if space_idx == i]).tolist()\n",
    "        indices = np.hstack([time_idx for time_idx, space_idx in zip(self.time_idx_exp, self.space_group_idx) if space_idx == i]).tolist()\n",
    "        return lats_in_space_group, lons_in_space_group, indices\n",
    "\n",
    "    def map_match(self):\n",
    "        \"\"\"\n",
    "        CALLED BY GET_POINTS_INFO\n",
    "\n",
    "        For each of the k space groups:\n",
    "            get all points in that group, \n",
    "            map match all points using that road network\n",
    "        Return the matching edges and distance from edge for each point\n",
    "            in sorted order (sorted like original df: by traj_id and timestamp)\n",
    "        \"\"\"\n",
    "        edges_all = []\n",
    "        distances_all = []\n",
    "        u_distances_all = []\n",
    "        v_distances_all = []\n",
    "        attributes_all = []\n",
    "        indices_all = []\n",
    "\t\n",
    "        desired_cols = ['osmid', 'highway', 'maxspeed', 'oneway', 'lanes']\n",
    "\n",
    "        for i in range(self.k):\n",
    "\n",
    "            Y, X, all_t_idx_for_s = self.get_all_space_group_points(i)\n",
    "            G = self.get_road_network(self.space_group_mbrs[i])\n",
    "            e, d = ox.distance.nearest_edges(G, X, Y, return_dist=True)\n",
    "\n",
    "            X_arr = np.array(X)\n",
    "            Y_arr = np.array(Y)\n",
    "            e_arr = np.array(e, dtype=object)\n",
    "            \n",
    "            u_nodes = [tup[0] for tup in e_arr]\n",
    "            v_nodes = [tup[1] for tup in e_arr]\n",
    "\n",
    "            u_coords_y = np.array([G.nodes[u]['y'] for u in u_nodes])\n",
    "            u_coords_x = np.array([G.nodes[u]['x'] for u in u_nodes])\n",
    "            v_coords_y = np.array([G.nodes[v]['y'] for v in v_nodes])\n",
    "            v_coords_x = np.array([G.nodes[v]['x'] for v in v_nodes])\n",
    "\n",
    "            u_dist = np.round(ox.distance.great_circle(Y_arr, X_arr, u_coords_y, u_coords_x, earth_radius = 6371.009),\n",
    "                              self.round_to)\n",
    "            v_dist = np.round(ox.distance.great_circle(Y_arr, X_arr, v_coords_y, v_coords_x, earth_radius = 6371.009),\n",
    "                              self.round_to)\n",
    "            \n",
    "            e_gdfs = ox.convert.graph_to_gdfs(G, nodes=False, edges = True)\n",
    "            e_gdfs = e_gdfs.assign(**{col: e_gdfs.get(col, np.nan) for col in desired_cols})\n",
    "\n",
    "            e_df = e_gdfs.loc[pd.Index(e), desired_cols]\n",
    "\n",
    "            edges_all.append(e_arr)\n",
    "            distances_all.append(np.array(d))\n",
    "            u_distances_all.append(u_dist)\n",
    "            v_distances_all.append(v_dist)\n",
    "            attributes_all.append(e_df.to_numpy())\n",
    "            indices_all.append(np.array(all_t_idx_for_s))\n",
    "\n",
    "        indices_list = np.hstack(indices_all)\n",
    "        order = np.argsort(indices_list)\n",
    "\n",
    "        edges_list = np.hstack(edges_all)\n",
    "        distance_list = np.hstack(distances_all)\n",
    "        u_dist_list = np.hstack(u_distances_all)\n",
    "        v_dist_list = np.hstack(v_distances_all)\n",
    "        attributes_list = np.vstack(attributes_all)\n",
    "\n",
    "        sorted_edges = edges_list[order].tolist()\n",
    "        sorted_distances = distance_list[order].tolist()\n",
    "        sorted_u_dists = u_dist_list[order].tolist()\n",
    "        sorted_v_dists = v_dist_list[order].tolist()\n",
    "        sorted_attributes = attributes_list[order].tolist()\n",
    "\n",
    "        return sorted_edges, sorted_distances, sorted_u_dists, sorted_v_dists, sorted_attributes\n",
    "    \n",
    "    def get_point_info(self):\n",
    "        \"\"\"\n",
    "        Return an np array with all the points in df \n",
    "            ordered by their trajectory ids and timestamp.\n",
    "\n",
    "            Currently array only has trajector id, speed, edge, \n",
    "            and distance from edge of each point\n",
    "        \"\"\"\n",
    "        edges, distances, u_dist, v_dist, osm_attr = self.map_match()\n",
    "        u, v, k = zip(*edges)\n",
    "        osmid, hway, maxspeed, oneway, lanes = zip(*osm_attr)\n",
    "        base_df = np.stack([self.traj_ids, self.timestamps, self.speeds, osmid, hway, maxspeed, oneway, lanes, u, v, k, u_dist, v_dist, distances]).transpose()\n",
    "        return base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4d57cfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time group index: [6, 8, 13, 18]\n",
      "\n",
      "time index expanded: [array([0, 1, 2, 3, 4, 5]), array([6, 7]), array([ 8,  9, 10, 11, 12]), array([13, 14, 15, 16, 17]), array([18, 19, 20])]\n",
      "\n",
      "space group MBRs: [(-122.474827, 37.718306999999996, -122.46922320013, 37.72391079987), (-122.47020520113, 37.72292879887, -122.46809320113, 37.72504079887), (-122.47134503113, 37.721788968869994, -122.47028927787, 37.722844722130006), (-122.470129278, 37.72300472199999, -122.469111109, 37.724022891)]\n",
      "\n",
      "space group index: [2 1 0 1 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "partition = DataPartition(df)\n",
    "partition.print_group_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "98c4caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = partition.get_point_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d82e2b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traj_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>speed</th>\n",
       "      <th>osmid</th>\n",
       "      <th>highway</th>\n",
       "      <th>maxspeed</th>\n",
       "      <th>oneway</th>\n",
       "      <th>lanes</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>k</th>\n",
       "      <th>u_d</th>\n",
       "      <th>v_d</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:31:20</td>\n",
       "      <td>31.049856</td>\n",
       "      <td>147496081</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65344136</td>\n",
       "      <td>1777579466</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460944</td>\n",
       "      <td>0.474388</td>\n",
       "      <td>0.004706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:31:40</td>\n",
       "      <td>48.232541</td>\n",
       "      <td>147496081</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65344136</td>\n",
       "      <td>1777579466</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518779</td>\n",
       "      <td>0.534675</td>\n",
       "      <td>0.004906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:32:00</td>\n",
       "      <td>29.212743</td>\n",
       "      <td>147496081</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65344136</td>\n",
       "      <td>1777579466</td>\n",
       "      <td>0</td>\n",
       "      <td>0.297865</td>\n",
       "      <td>0.310826</td>\n",
       "      <td>0.003079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:32:20</td>\n",
       "      <td>29.600432</td>\n",
       "      <td>147496081</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65344136</td>\n",
       "      <td>1777579466</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139672</td>\n",
       "      <td>0.150895</td>\n",
       "      <td>0.001499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:32:40</td>\n",
       "      <td>14.546215</td>\n",
       "      <td>147496081</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1777579592</td>\n",
       "      <td>1777579506</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024216</td>\n",
       "      <td>0.02883</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:33:20</td>\n",
       "      <td>28.834413</td>\n",
       "      <td>147496081</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65318455</td>\n",
       "      <td>1777579449</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048614</td>\n",
       "      <td>0.12305</td>\n",
       "      <td>0.000524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:33:40</td>\n",
       "      <td>7.094456</td>\n",
       "      <td>166304405</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315418475</td>\n",
       "      <td>65301236</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006427</td>\n",
       "      <td>0.00575</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:35:00</td>\n",
       "      <td>9.695746</td>\n",
       "      <td>8917465</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315419037</td>\n",
       "      <td>315419038</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049153</td>\n",
       "      <td>0.046484</td>\n",
       "      <td>0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:36:00</td>\n",
       "      <td>28.534377</td>\n",
       "      <td>147496081</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1777579592</td>\n",
       "      <td>1777579506</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023167</td>\n",
       "      <td>0.029242</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:36:20</td>\n",
       "      <td>28.830454</td>\n",
       "      <td>33868992</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65358673</td>\n",
       "      <td>65358669</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.053564</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:36:40</td>\n",
       "      <td>14.788858</td>\n",
       "      <td>572348897</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8276553001</td>\n",
       "      <td>65321802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15774</td>\n",
       "      <td>0.146603</td>\n",
       "      <td>0.000352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:37:20</td>\n",
       "      <td>29.212563</td>\n",
       "      <td>33868992</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65358673</td>\n",
       "      <td>65358669</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>0.050553</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:37:40</td>\n",
       "      <td>14.801458</td>\n",
       "      <td>147496081</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1777579592</td>\n",
       "      <td>65344139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02161</td>\n",
       "      <td>0.021246</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:38:20</td>\n",
       "      <td>29.089633</td>\n",
       "      <td>166304349</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65348253</td>\n",
       "      <td>315418887</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037244</td>\n",
       "      <td>0.037494</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:38:40</td>\n",
       "      <td>28.834233</td>\n",
       "      <td>166304405</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315418464</td>\n",
       "      <td>315418465</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:39:00</td>\n",
       "      <td>8.108002</td>\n",
       "      <td>8916641</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65301266</td>\n",
       "      <td>65301243</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062174</td>\n",
       "      <td>0.146711</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:40:10</td>\n",
       "      <td>58.170626</td>\n",
       "      <td>166304405</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315418464</td>\n",
       "      <td>315418465</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:40:20</td>\n",
       "      <td>28.534197</td>\n",
       "      <td>166304349</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65348253</td>\n",
       "      <td>315418887</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034671</td>\n",
       "      <td>0.03509</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:40:40</td>\n",
       "      <td>28.830274</td>\n",
       "      <td>8917465</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65318455</td>\n",
       "      <td>315419038</td>\n",
       "      <td>0</td>\n",
       "      <td>0.098616</td>\n",
       "      <td>0.098856</td>\n",
       "      <td>0.000945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:41:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8917465</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65318455</td>\n",
       "      <td>315419038</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257874</td>\n",
       "      <td>0.259009</td>\n",
       "      <td>0.002532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:41:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8917465</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65318455</td>\n",
       "      <td>315419038</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257874</td>\n",
       "      <td>0.259009</td>\n",
       "      <td>0.002532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   traj_id           timestamp      speed      osmid      highway maxspeed  \\\n",
       "0   0_10-0 2021-01-01 07:31:20  31.049856  147496081  residential      NaN   \n",
       "1   0_10-0 2021-01-01 07:31:40  48.232541  147496081  residential      NaN   \n",
       "2   0_10-0 2021-01-01 07:32:00  29.212743  147496081  residential      NaN   \n",
       "3   0_10-0 2021-01-01 07:32:20  29.600432  147496081  residential      NaN   \n",
       "4   0_10-0 2021-01-01 07:32:40  14.546215  147496081  residential      NaN   \n",
       "5   0_10-0 2021-01-01 07:33:20  28.834413  147496081  residential      NaN   \n",
       "6   0_10-0 2021-01-01 07:33:40   7.094456  166304405  residential      NaN   \n",
       "7   0_10-0 2021-01-01 07:35:00   9.695746    8917465  residential      NaN   \n",
       "8   0_10-0 2021-01-01 07:36:00  28.534377  147496081  residential      NaN   \n",
       "9   0_10-0 2021-01-01 07:36:20  28.830454   33868992  residential      NaN   \n",
       "10  0_10-0 2021-01-01 07:36:40  14.788858  572348897  residential      NaN   \n",
       "11  0_10-0 2021-01-01 07:37:20  29.212563   33868992  residential      NaN   \n",
       "12  0_10-0 2021-01-01 07:37:40  14.801458  147496081  residential      NaN   \n",
       "13  0_10-0 2021-01-01 07:38:20  29.089633  166304349  residential      NaN   \n",
       "14  0_10-0 2021-01-01 07:38:40  28.834233  166304405  residential      NaN   \n",
       "15  0_10-0 2021-01-01 07:39:00   8.108002    8916641  residential      NaN   \n",
       "16  0_10-0 2021-01-01 07:40:10  58.170626  166304405  residential      NaN   \n",
       "17  0_10-0 2021-01-01 07:40:20  28.534197  166304349  residential      NaN   \n",
       "18  0_10-0 2021-01-01 07:40:40  28.830274    8917465  residential      NaN   \n",
       "19  0_10-0 2021-01-01 07:41:00        0.0    8917465  residential      NaN   \n",
       "20  0_10-0 2021-01-01 07:41:30        0.0    8917465  residential      NaN   \n",
       "\n",
       "   oneway lanes           u           v  k       u_d       v_d      dist  \n",
       "0   False   NaN    65344136  1777579466  0  0.460944  0.474388  0.004706  \n",
       "1   False   NaN    65344136  1777579466  0  0.518779  0.534675  0.004906  \n",
       "2   False   NaN    65344136  1777579466  0  0.297865  0.310826  0.003079  \n",
       "3   False   NaN    65344136  1777579466  0  0.139672  0.150895  0.001499  \n",
       "4   False   NaN  1777579592  1777579506  0  0.024216   0.02883  0.000272  \n",
       "5   False   NaN    65318455  1777579449  0  0.048614   0.12305  0.000524  \n",
       "6    True   NaN   315418475    65301236  0  0.006427   0.00575  0.000043  \n",
       "7   False   NaN   315419037   315419038  0  0.049153  0.046484  0.000436  \n",
       "8   False   NaN  1777579592  1777579506  0  0.023167  0.029242  0.000259  \n",
       "9   False   NaN    65358673    65358669  0  0.009177  0.053564  0.000088  \n",
       "10  False   NaN  8276553001    65321802  0   0.15774  0.146603  0.000352  \n",
       "11  False   NaN    65358673    65358669  0  0.008399  0.050553  0.000089  \n",
       "12  False   NaN  1777579592    65344139  0   0.02161  0.021246  0.000223  \n",
       "13  False   NaN    65348253   315418887  0  0.037244  0.037494  0.000346  \n",
       "14   True   NaN   315418464   315418465  0  0.004759  0.003785  0.000027  \n",
       "15  False   NaN    65301266    65301243  0  0.062174  0.146711  0.000561  \n",
       "16   True   NaN   315418464   315418465  0  0.006579  0.001536  0.000016  \n",
       "17  False   NaN    65348253   315418887  0  0.034671   0.03509  0.000322  \n",
       "18  False   NaN    65318455   315419038  0  0.098616  0.098856  0.000945  \n",
       "19  False   NaN    65318455   315419038  0  0.257874  0.259009  0.002532  \n",
       "20  False   NaN    65318455   315419038  0  0.257874  0.259009  0.002532  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(new, columns=[\"traj_id\", \"timestamp\", \"speed\", \"osmid\", \"highway\", \"maxspeed\", \"oneway\", \"lanes\", \"u\", \"v\", \"k\", \"u_d\", \"v_d\", \"dist\"])\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b55e9e",
   "metadata": {},
   "source": [
    "AUG 4 OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a2c9eb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traj_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>speed</th>\n",
       "      <th>osmid</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>k</th>\n",
       "      <th>u_d</th>\n",
       "      <th>v_d</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:31:20</td>\n",
       "      <td>31.049856</td>\n",
       "      <td>166304349</td>\n",
       "      <td>315418888</td>\n",
       "      <td>65348253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106813</td>\n",
       "      <td>0.109707</td>\n",
       "      <td>0.001024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:31:40</td>\n",
       "      <td>48.232541</td>\n",
       "      <td>8917465</td>\n",
       "      <td>315419038</td>\n",
       "      <td>315419037</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046484</td>\n",
       "      <td>0.049153</td>\n",
       "      <td>0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:32:00</td>\n",
       "      <td>29.212743</td>\n",
       "      <td>166304349</td>\n",
       "      <td>65348253</td>\n",
       "      <td>315418887</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037244</td>\n",
       "      <td>0.037494</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:32:20</td>\n",
       "      <td>29.600432</td>\n",
       "      <td>166304349</td>\n",
       "      <td>315418888</td>\n",
       "      <td>65348253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121361</td>\n",
       "      <td>0.124439</td>\n",
       "      <td>0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:32:40</td>\n",
       "      <td>14.546215</td>\n",
       "      <td>166304349</td>\n",
       "      <td>315418888</td>\n",
       "      <td>65348253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280799</td>\n",
       "      <td>0.284635</td>\n",
       "      <td>0.002759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:33:20</td>\n",
       "      <td>28.834413</td>\n",
       "      <td>166304349</td>\n",
       "      <td>315418888</td>\n",
       "      <td>65348253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123885</td>\n",
       "      <td>0.12699</td>\n",
       "      <td>0.001194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:33:40</td>\n",
       "      <td>7.094456</td>\n",
       "      <td>166304349</td>\n",
       "      <td>65348253</td>\n",
       "      <td>315418887</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034671</td>\n",
       "      <td>0.03509</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:35:00</td>\n",
       "      <td>9.695746</td>\n",
       "      <td>147496081</td>\n",
       "      <td>1777579449</td>\n",
       "      <td>65318455</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022493</td>\n",
       "      <td>0.098616</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:36:00</td>\n",
       "      <td>28.534377</td>\n",
       "      <td>147496081</td>\n",
       "      <td>1777579449</td>\n",
       "      <td>65318455</td>\n",
       "      <td>0</td>\n",
       "      <td>0.180495</td>\n",
       "      <td>0.257874</td>\n",
       "      <td>0.001825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:36:20</td>\n",
       "      <td>28.830454</td>\n",
       "      <td>147496081</td>\n",
       "      <td>1777579449</td>\n",
       "      <td>65318455</td>\n",
       "      <td>0</td>\n",
       "      <td>0.180495</td>\n",
       "      <td>0.257874</td>\n",
       "      <td>0.001825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:36:40</td>\n",
       "      <td>14.788858</td>\n",
       "      <td>147496081</td>\n",
       "      <td>65344136</td>\n",
       "      <td>1777579466</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460944</td>\n",
       "      <td>0.474388</td>\n",
       "      <td>0.004706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:37:20</td>\n",
       "      <td>29.212563</td>\n",
       "      <td>147496081</td>\n",
       "      <td>65344136</td>\n",
       "      <td>1777579466</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518779</td>\n",
       "      <td>0.534675</td>\n",
       "      <td>0.004906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:37:40</td>\n",
       "      <td>14.801458</td>\n",
       "      <td>147496081</td>\n",
       "      <td>65344136</td>\n",
       "      <td>1777579466</td>\n",
       "      <td>0</td>\n",
       "      <td>0.297865</td>\n",
       "      <td>0.310826</td>\n",
       "      <td>0.003079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:38:20</td>\n",
       "      <td>29.089633</td>\n",
       "      <td>147496081</td>\n",
       "      <td>65344136</td>\n",
       "      <td>1777579466</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139672</td>\n",
       "      <td>0.150895</td>\n",
       "      <td>0.001499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:38:40</td>\n",
       "      <td>28.834233</td>\n",
       "      <td>147496081</td>\n",
       "      <td>1777579592</td>\n",
       "      <td>1777579506</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024216</td>\n",
       "      <td>0.02883</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:39:00</td>\n",
       "      <td>8.108002</td>\n",
       "      <td>147496081</td>\n",
       "      <td>65318455</td>\n",
       "      <td>1777579449</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048614</td>\n",
       "      <td>0.12305</td>\n",
       "      <td>0.000524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:40:10</td>\n",
       "      <td>58.170626</td>\n",
       "      <td>8917465</td>\n",
       "      <td>65318455</td>\n",
       "      <td>315419038</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114807</td>\n",
       "      <td>0.115253</td>\n",
       "      <td>0.001106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:40:20</td>\n",
       "      <td>28.534197</td>\n",
       "      <td>8917465</td>\n",
       "      <td>65318455</td>\n",
       "      <td>315419038</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272602</td>\n",
       "      <td>0.273767</td>\n",
       "      <td>0.002679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:40:40</td>\n",
       "      <td>28.830274</td>\n",
       "      <td>8917465</td>\n",
       "      <td>65318455</td>\n",
       "      <td>315419038</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432586</td>\n",
       "      <td>0.433943</td>\n",
       "      <td>0.004275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:41:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8917465</td>\n",
       "      <td>65318455</td>\n",
       "      <td>315419038</td>\n",
       "      <td>0</td>\n",
       "      <td>0.268474</td>\n",
       "      <td>0.26963</td>\n",
       "      <td>0.002638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0_10-0</td>\n",
       "      <td>2021-01-01 07:41:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8917465</td>\n",
       "      <td>65318455</td>\n",
       "      <td>315419038</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106997</td>\n",
       "      <td>0.107351</td>\n",
       "      <td>0.001028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   traj_id           timestamp      speed      osmid           u           v  \\\n",
       "0   0_10-0 2021-01-01 07:31:20  31.049856  166304349   315418888    65348253   \n",
       "1   0_10-0 2021-01-01 07:31:40  48.232541    8917465   315419038   315419037   \n",
       "2   0_10-0 2021-01-01 07:32:00  29.212743  166304349    65348253   315418887   \n",
       "3   0_10-0 2021-01-01 07:32:20  29.600432  166304349   315418888    65348253   \n",
       "4   0_10-0 2021-01-01 07:32:40  14.546215  166304349   315418888    65348253   \n",
       "5   0_10-0 2021-01-01 07:33:20  28.834413  166304349   315418888    65348253   \n",
       "6   0_10-0 2021-01-01 07:33:40   7.094456  166304349    65348253   315418887   \n",
       "7   0_10-0 2021-01-01 07:35:00   9.695746  147496081  1777579449    65318455   \n",
       "8   0_10-0 2021-01-01 07:36:00  28.534377  147496081  1777579449    65318455   \n",
       "9   0_10-0 2021-01-01 07:36:20  28.830454  147496081  1777579449    65318455   \n",
       "10  0_10-0 2021-01-01 07:36:40  14.788858  147496081    65344136  1777579466   \n",
       "11  0_10-0 2021-01-01 07:37:20  29.212563  147496081    65344136  1777579466   \n",
       "12  0_10-0 2021-01-01 07:37:40  14.801458  147496081    65344136  1777579466   \n",
       "13  0_10-0 2021-01-01 07:38:20  29.089633  147496081    65344136  1777579466   \n",
       "14  0_10-0 2021-01-01 07:38:40  28.834233  147496081  1777579592  1777579506   \n",
       "15  0_10-0 2021-01-01 07:39:00   8.108002  147496081    65318455  1777579449   \n",
       "16  0_10-0 2021-01-01 07:40:10  58.170626    8917465    65318455   315419038   \n",
       "17  0_10-0 2021-01-01 07:40:20  28.534197    8917465    65318455   315419038   \n",
       "18  0_10-0 2021-01-01 07:40:40  28.830274    8917465    65318455   315419038   \n",
       "19  0_10-0 2021-01-01 07:41:00        0.0    8917465    65318455   315419038   \n",
       "20  0_10-0 2021-01-01 07:41:30        0.0    8917465    65318455   315419038   \n",
       "\n",
       "    k       u_d       v_d      dist  \n",
       "0   0  0.106813  0.109707  0.001024  \n",
       "1   0  0.046484  0.049153  0.000436  \n",
       "2   0  0.037244  0.037494  0.000346  \n",
       "3   0  0.121361  0.124439  0.001169  \n",
       "4   0  0.280799  0.284635  0.002759  \n",
       "5   0  0.123885   0.12699  0.001194  \n",
       "6   0  0.034671   0.03509  0.000322  \n",
       "7   0  0.022493  0.098616  0.000247  \n",
       "8   0  0.180495  0.257874  0.001825  \n",
       "9   0  0.180495  0.257874  0.001825  \n",
       "10  0  0.460944  0.474388  0.004706  \n",
       "11  0  0.518779  0.534675  0.004906  \n",
       "12  0  0.297865  0.310826  0.003079  \n",
       "13  0  0.139672  0.150895  0.001499  \n",
       "14  0  0.024216   0.02883  0.000272  \n",
       "15  0  0.048614   0.12305  0.000524  \n",
       "16  0  0.114807  0.115253  0.001106  \n",
       "17  0  0.272602  0.273767  0.002679  \n",
       "18  0  0.432586  0.433943  0.004275  \n",
       "19  0  0.268474   0.26963  0.002638  \n",
       "20  0  0.106997  0.107351  0.001028  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(new, columns=[\"traj_id\", \"timestamp\", \"speed\", \"osmid\", \"u\", \"v\", \"k\", \"u_d\", \"v_d\", \"dist\"])\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bd64fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec17b2",
   "metadata": {},
   "source": [
    "# Edge Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c5b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, u, v, k):\n",
    "\n",
    "        # GENERAL INFO\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "        self.k = k\n",
    "        self.osmid = None\n",
    "        self.prev_p = None\n",
    "        self.count = 0\n",
    "\n",
    "        # SPEED VALS\n",
    "        self.min_s = np.inf\n",
    "        self.max_s = -1\n",
    "        self.q1 = 0\n",
    "        self.q2 = 0\n",
    "        self.q3 = 0\n",
    "\n",
    "        # TO CALCULATE METADATA\n",
    "        self.u_to_v_count = 0\n",
    "        self.v_to_u_count = 0\n",
    "        self.max_dist = 0\n",
    "\n",
    "        # METADATA\n",
    "        self.oneway = True\n",
    "        self.expected_speed = None\n",
    "        self.speed_limit = None\n",
    "\n",
    "    def update(self, cur_p):\n",
    "        \"\"\"Update edge statistics using current point\"\"\"\n",
    "\n",
    "        # speed extrema\n",
    "        s = cur_p[\"speed\"]\n",
    "        self.min_s = min(self.min_s, s)\n",
    "        self.max_s = max(self.max_s, s)\n",
    "\n",
    "        # speed quantiles\n",
    "        #   computed using previous quantile value and new speed value\n",
    "        #   this got similar results to updating using the min and max alongise points\n",
    "        self.q1 = np.quantile([self.q1,s],q=0.25)\n",
    "        self.q2 = np.quantile([self.q2,s],q=0.5)\n",
    "        self.q3 = np.quantile([self.q3,s],q=0.75)\n",
    "\n",
    "        # max distance used to calculate number of lanes\n",
    "        self.max_dist = max(self.max_dist, cur_p[\"dist\"])\n",
    "\n",
    "        # direction of trajectory\n",
    "        # check if points are from same trajectory and w/in 2 mins\n",
    "        if self.prev_p is not None:\n",
    "            if cur_p[\"traj_id\"] == self.prev_p[\"traj_id\"]:\n",
    "                if(cur_p[\"timestamp\"] - self.prev_p[\"timestamp\"]).total_seconds() < 120:\n",
    "                    \n",
    "                    # compute direction\n",
    "                    if cur_p[\"u_d\"] < self.prev_p[\"u_d\"]:\n",
    "                        if cur_p[\"v_d\"] > self.prev_p[\"v_d\"]:\n",
    "                            self.v_to_u_count += 1\n",
    "                            print(f\"\\tv to u\")\n",
    "                        else:\n",
    "                            self.u_to_v_count += 1\n",
    "                            print(f\"\\tu to v\")\n",
    "                    else:\n",
    "                        if cur_p[\"v_d\"] > self.prev_p[\"v_d\"]:\n",
    "                            self.v_to_u_count += 1\n",
    "                            print(f\"\\tv to u\")\n",
    "                        else:\n",
    "                            self.u_to_v_count += 1\n",
    "                            print(f\"u to v\")\n",
    "        self.prev_p = cur_p\n",
    "\n",
    "        if self.osmid == None:\n",
    "            self.osmid = cur_p[\"osmid\"]\n",
    "\n",
    "        # updating number of points for edge\n",
    "        self.count += 1\n",
    "\n",
    "    def get_oneway(self):\n",
    "        \"\"\"Use u to v/ v to u counts to determine if edge is a oneway\"\"\"\n",
    "        if (self.u_to_v_count == 0) or (self.v_to_u_count == 0):\n",
    "            assert self.oneway == True\n",
    "        else:\n",
    "            self.oneway = False\n",
    "        return\n",
    "\n",
    "    def get_expected_speed(self):\n",
    "        \"\"\"Expected speed = q2\"\"\"\n",
    "        self.expected_speed= round(self.q2,3)\n",
    "\n",
    "    def get_speed_limit(self):\n",
    "        \"\"\"\n",
    "        Return guess of legal speed limit\n",
    "            Guess: the closest multiple of ten greater than the maximum speed observed\n",
    "        \"\"\"\n",
    "        t = np.trunc(self.max_s/10)\n",
    "        self.speed_limit = int((t*10) + 10)\n",
    "\n",
    "\n",
    "class EdgesSet:\n",
    "    def __init__(self):\n",
    "        self.edges = {}  # key: (u, v, k) -> value: Edge object\n",
    "\n",
    "    def update_edge(self,cur_p):\n",
    "        \"\"\"\n",
    "        Given an edge index (u, v, k) and the current point\n",
    "\n",
    "            - Add edge to set if it is not in it yet\n",
    "            - Update edge statistics given current point cur_p\n",
    "        \"\"\"\n",
    "        idx = (cur_p[\"u\"], cur_p[\"v\"], cur_p[\"k\"])\n",
    "        if idx not in self.edges:\n",
    "            print(\"new edge!\")\n",
    "            self.edges[idx] = Edge(cur_p[\"u\"], cur_p[\"v\"], cur_p[\"k\"])\n",
    "        self.edges[idx].update(cur_p)\n",
    "\n",
    "    def get_edge(self, u,v,k):\n",
    "        \"\"\"Return edge at given index\"\"\"\n",
    "        return self.edges.get((u,v,k), None)\n",
    "    \n",
    "    def get_all_idx(self):\n",
    "        return self.edges.keys()\n",
    "    \n",
    "    def compute_metadata(self, u, v, k):\n",
    "        \n",
    "        edge = self.edges[(u,v,k)]\n",
    "\n",
    "        edge.get_oneway()\n",
    "        edge.get_expected_speed()\n",
    "        edge.get_speed_limit()\n",
    "\n",
    "        return edge.oneway, edge.expected_speed, edge.speed_limit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0097dfeb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b0704",
   "metadata": {},
   "source": [
    "# Testing edge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8b134d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_1 = new_df.iloc[12]\n",
    "row_2 = new_df.iloc[13]\n",
    "row3 = new_df.iloc[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7a950c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new edge!\n"
     ]
    }
   ],
   "source": [
    "es = EdgesSet()\n",
    "es.update_edge(row_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8dd0b956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "\tv to u\n",
      "0 1\n",
      "0 1\n",
      "\tu to v\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "ce = es.get_edge(row_1[\"u\"], row_1[\"v\"], row_1[\"k\"])\n",
    "print(ce.u_to_v_count, ce.v_to_u_count)\n",
    "es.update_edge(row_2)\n",
    "ce2 = es.get_edge(row_1[\"u\"], row_1[\"v\"], row_1[\"k\"])\n",
    "print(ce2.u_to_v_count, ce2.v_to_u_count)\n",
    "ce3 = es.get_edge(row_2[\"u\"], row_2[\"v\"], row_2[\"k\"])\n",
    "print(ce3.u_to_v_count, ce3.v_to_u_count)\n",
    "es.update_edge(row3)\n",
    "ce4 = es.get_edge(row3[\"u\"], row3[\"v\"], row3[\"k\"])\n",
    "print(ce4.u_to_v_count, ce4.v_to_u_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "38dce6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\toneway should be False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, np.float64(23.54), 30)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_metadata = es.compute_metadata(row3[\"u\"], row3[\"v\"], row3[\"k\"])\n",
    "e_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "64e8dadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_metadata[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1c7f84a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.089632829373645"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce5 = es.get_edge(row3[\"u\"], row3[\"v\"], row3[\"k\"])\n",
    "ce5.max_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ffa662e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([(65344136, 1777579466, 0)])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keys = es.get_all_idx()\n",
    "all_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02595ab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f2fd6a",
   "metadata": {},
   "source": [
    "# Test updating quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c16b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_min_p = 1000\n",
    "old_max_p =-1\n",
    "q1 = 0\n",
    "q2 = 0\n",
    "q3 = 0\n",
    "\n",
    "all_points = [[0,12,20,13,17.6,19.1,11.2,15.01,18,12,12.1,31,10,2.91,14.4,8.11,8.355,8.2,19,23],\n",
    "[23,19,8.2,8.355,8.11,14.4,2.91,10,31,12.1,12,18,15.01,11.2,19.1,17.6,13,20,12,0],\n",
    "[14.4,8.11,17.6,2.91,12.1,20,11.2,13,0,8.355,18,12,19.1,10,15.01,19,8.2,31,23,12],\n",
    "[12,11.2,20,14.4,12.1,10,0,13,2.91,8.2,17.6,19,8.11,15.01,18,8.355,31,19.1,23,12],\n",
    "[19.1,12.1,0,23,12,15.01,2.91,19,8.11,14.4,18,17.6,31,13,8.2,10,20,8.355,11.2,12],\n",
    "[2.91,19.1,10,12.1,23,11.2,8.2,13,15.01,20,14.4,0,8.11,18,8.355,17.6,12,31,12,19],\n",
    "[12.1,10,12,2.91,18,0,8.2,11.2,15.01,20,17.6,19.1,13,14.4,8.11,12,8.355,23,31,19],\n",
    "[19.1,13,17.6,12.1,20,12,15.01,18,2.91,14.4,10,12,0,8.11,23,31,8.355,8.2,19,11.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "32509237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1: 13.752876414446398\n",
      "q1: 12.765331849498468\n",
      "q1: 13.23578642318422\n",
      "q1: 13.40854951930006\n",
      "q1: 10.358492551335749\n",
      "q1: 14.564726536199124\n",
      "q1: 17.510529550181875\n",
      "q1: 11.231204498319705\n"
     ]
    }
   ],
   "source": [
    "# using min / max value saved as a point to compute quantiles\n",
    "# if it has not been used before\n",
    "for points in all_points:\n",
    "    for p in points:\n",
    "\n",
    "        # print(f\"\\np: {p}\")\n",
    "        new_min_p = min(old_min_p, p)\n",
    "        new_max_p = max(old_max_p, p)\n",
    "        # print(f\"new min: {new_min_p} \\told min: {old_min_p}\")\n",
    "        # print(f\"new max: {new_max_p} \\told max: {old_max_p}\")\n",
    "        \n",
    "        if new_min_p != old_min_p:\n",
    "            # print(f\"\\tnew min != old min\")\n",
    "            if new_min_p != p:\n",
    "                # print(f\"\\tmin != p\")\n",
    "                if new_max_p != old_max_p:\n",
    "                    # print(f\"\\tnew max != old max\")\n",
    "                    if new_max_p != p:\n",
    "                        # print(f\"\\tmax != p\")\n",
    "                        q1 = np.quantile([q1,new_max_p,new_min_p, p], q1)\n",
    "                    q1 = np.quantile([q1,new_max_p,new_min_p], q=0.25)\n",
    "                q1 = np.quantile([q1,new_min_p], q=0.25)\n",
    "        \n",
    "            q1 = np.quantile([q1,new_min_p], q=0.25)\n",
    "        else:\n",
    "            # print(f\"\\tnew min == old min\")\n",
    "            if new_min_p != p:\n",
    "                # print(f\"\\tmin != p\")\n",
    "                if new_max_p != old_max_p:\n",
    "                    # print(f\"\\tnew max != old max\")\n",
    "                    if new_max_p != p:\n",
    "                        # print(f\"\\tmax != p\")\n",
    "                        q1 = np.quantile([q1,new_max_p, p], q1)\n",
    "                    q1 = np.quantile([q1,new_max_p], q=0.25)\n",
    "                q1 = np.quantile([q1,p], q=0.25)\n",
    "            q1 = q1\n",
    "\n",
    "        old_min_p = new_min_p\n",
    "        old_max_p = new_max_p\n",
    "\n",
    "        # print(f\"min: {old_min_p}\")\n",
    "        # print(f\"max: {old_max_p}\")\n",
    "    print(f\"q1: {q1}\")\n",
    "    # print(f\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df43bf0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9c5c60",
   "metadata": {},
   "source": [
    "# Explore to get travel direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ea9cb755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import osmnx as ox\n",
    "# ox.Config(log_console=True, use_cache=True)\n",
    "\n",
    "# get graph and define a reference point\n",
    "G = ox.graph_from_point((13.743942, 100.570006), network_type='drive', dist=350, simplify=True)\n",
    "lat = 13.744001\n",
    "lng = 100.570457\n",
    "\n",
    "# get nearest node incident to nearest edge to reference point\n",
    "geom, u, v = ox.nearest_edges(G, Y=lat, X=lng)\n",
    "nodes, edges = ox.convert.graph_to_gdfs(G, nodes=True, edges = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc813429",
   "metadata": {},
   "outputs": [],
   "source": [
    "ox.plot_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bf5ab06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>street_count</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osmid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270672090</th>\n",
       "      <td>13.743376</td>\n",
       "      <td>100.566871</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (100.56687 13.74338)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270672773</th>\n",
       "      <td>13.740868</td>\n",
       "      <td>100.572794</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (100.57279 13.74087)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270672774</th>\n",
       "      <td>13.742383</td>\n",
       "      <td>100.572928</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (100.57293 13.74238)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270672775</th>\n",
       "      <td>13.742480</td>\n",
       "      <td>100.572360</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (100.57236 13.74248)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270673030</th>\n",
       "      <td>13.742646</td>\n",
       "      <td>100.571599</td>\n",
       "      <td>4</td>\n",
       "      <td>POINT (100.5716 13.74265)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   y           x  street_count                    geometry\n",
       "osmid                                                                     \n",
       "270672090  13.743376  100.566871             3  POINT (100.56687 13.74338)\n",
       "270672773  13.740868  100.572794             3  POINT (100.57279 13.74087)\n",
       "270672774  13.742383  100.572928             3  POINT (100.57293 13.74238)\n",
       "270672775  13.742480  100.572360             3  POINT (100.57236 13.74248)\n",
       "270673030  13.742646  100.571599             4   POINT (100.5716 13.74265)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "438911a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>osmid</th>\n",
       "      <th>highway</th>\n",
       "      <th>maxspeed</th>\n",
       "      <th>oneway</th>\n",
       "      <th>reversed</th>\n",
       "      <th>length</th>\n",
       "      <th>geometry</th>\n",
       "      <th>lanes</th>\n",
       "      <th>name</th>\n",
       "      <th>bridge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">270672090</th>\n",
       "      <th>3483658791</th>\n",
       "      <th>0</th>\n",
       "      <td>25975737</td>\n",
       "      <td>residential</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>340.300840</td>\n",
       "      <td>LINESTRING (100.56687 13.74338, 100.56713 13.7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280389438</th>\n",
       "      <th>0</th>\n",
       "      <td>25975737</td>\n",
       "      <td>residential</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>205.373730</td>\n",
       "      <td>LINESTRING (100.56687 13.74338, 100.56653 13.7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">270672774</th>\n",
       "      <th>11779709621</th>\n",
       "      <th>0</th>\n",
       "      <td>[1268298873, 340273010]</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[False, True]</td>\n",
       "      <td>215.723913</td>\n",
       "      <td>LINESTRING (100.57293 13.74238, 100.57314 13.7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270672773</th>\n",
       "      <th>0</th>\n",
       "      <td>342245569</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>169.070210</td>\n",
       "      <td>LINESTRING (100.57293 13.74238, 100.57291 13.7...</td>\n",
       "      <td>2</td>\n",
       "      <td>ซอยสุขุมวิท 39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270672775</th>\n",
       "      <th>270672774</th>\n",
       "      <th>0</th>\n",
       "      <td>342245569</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>62.370015</td>\n",
       "      <td>LINESTRING (100.57236 13.74248, 100.57293 13.7...</td>\n",
       "      <td>2</td>\n",
       "      <td>ซอยสุขุมวิท 39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             osmid      highway maxspeed  \\\n",
       "u         v           key                                                  \n",
       "270672090 3483658791  0                   25975737  residential       30   \n",
       "          280389438   0                   25975737  residential       30   \n",
       "270672774 11779709621 0    [1268298873, 340273010]  residential      NaN   \n",
       "          270672773   0                  342245569     tertiary       30   \n",
       "270672775 270672774   0                  342245569     tertiary       30   \n",
       "\n",
       "                           oneway       reversed      length  \\\n",
       "u         v           key                                      \n",
       "270672090 3483658791  0     False          False  340.300840   \n",
       "          280389438   0     False           True  205.373730   \n",
       "270672774 11779709621 0     False  [False, True]  215.723913   \n",
       "          270672773   0      True          False  169.070210   \n",
       "270672775 270672774   0      True          False   62.370015   \n",
       "\n",
       "                                                                    geometry  \\\n",
       "u         v           key                                                      \n",
       "270672090 3483658791  0    LINESTRING (100.56687 13.74338, 100.56713 13.7...   \n",
       "          280389438   0    LINESTRING (100.56687 13.74338, 100.56653 13.7...   \n",
       "270672774 11779709621 0    LINESTRING (100.57293 13.74238, 100.57314 13.7...   \n",
       "          270672773   0    LINESTRING (100.57293 13.74238, 100.57291 13.7...   \n",
       "270672775 270672774   0    LINESTRING (100.57236 13.74248, 100.57293 13.7...   \n",
       "\n",
       "                          lanes            name bridge  \n",
       "u         v           key                               \n",
       "270672090 3483658791  0     NaN             NaN    NaN  \n",
       "          280389438   0     NaN             NaN    NaN  \n",
       "270672774 11779709621 0     NaN             NaN    NaN  \n",
       "          270672773   0       2  ซอยสุขุมวิท 39    NaN  \n",
       "270672775 270672774   0       2  ซอยสุขุมวิท 39    NaN  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c0ed4f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u            v            key\n",
       "270672090    3483658791   0                     25975737\n",
       "             280389438    0                     25975737\n",
       "270672774    11779709621  0      [1268298873, 340273010]\n",
       "             270672773    0                    342245569\n",
       "270672775    270672774    0                    342245569\n",
       "                                          ...           \n",
       "9702307308   9702307309   0                   1055897274\n",
       "9702307309   283365694    0                     25975734\n",
       "             283364717    0                     25975734\n",
       "             9702307308   0                   1055897274\n",
       "11779709621  270672774    0      [1268298873, 340273010]\n",
       "Name: osmid, Length: 73, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges['osmid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "38dba5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25975737"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.loc[( 270672090,  3483658791, 0)]['osmid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b84e3b",
   "metadata": {},
   "source": [
    "Notes on accessing edges and nodes objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edges.index   # gives multiindex object of all (u,v,key) edge indices\n",
    "# edge_endpoints = edges['name'].index.tolist()   # gives (u,v,key) edge indices in a list\n",
    "# edges.loc[(  270672090,  3483658791, 0)]    # get specific edge info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2075b177",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03458863",
   "metadata": {},
   "source": [
    "Haversine formula code below copied from: https://gist.github.com/rochacbruno/2883505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16596305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Haversine formula example in Python\n",
    "# Author: Wayne Dyck\n",
    "\n",
    "import math\n",
    "\n",
    "def distance(origin, destination):\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371 # km\n",
    "\n",
    "    dlat = math.radians(lat2-lat1)\n",
    "    dlon = math.radians(lon2-lon1)\n",
    "    a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
    "        * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapedia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
